{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39a659ae-5c1d-4472-aba4-138797d82551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlevel 2\\nScript 3: EDA preproc\\nExtraction of scl and scr. Currently using flirt package which claims that raw data can directly be supplied to extract scl and scr. \\nThis can be replaced/added with any other verified preprocessing strategy/package if deemed necessary\\nThe extracted (and aggregated) scr and scl could optionally be stored as numpy arrays and saved\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "level 2\n",
    "Script 3: EDA preproc\n",
    "Extraction of scl and scr. Currently using flirt package which claims that raw data can directly be supplied to extract scl and scr. \n",
    "This can be replaced/added with any other verified preprocessing strategy/package if deemed necessary - Combination of Irene, Taylor and Makowski\n",
    "The extracted (and aggregated) scr and scl could optionally be stored as numpy arrays and saved (for method 1; method 2 takes care of itself)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46969e74-e08b-45d6-b447-1e6d8b74da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "920989f8-4b1c-4d02-ba29-b67b9e39296a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\envs\\empatica\\Lib\\site-packages\\flirt\\lib\\entropy\\fractal.py:106: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit('float64(float64[:], int32)')\n"
     ]
    }
   ],
   "source": [
    "#pip install flirt\n",
    "\"\"\"\n",
    "flirt imports\n",
    "\"\"\"\n",
    "import flirt.with_\n",
    "flirt.with_.me()\n",
    "import flirt.reader.empatica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7722f6e4-9fa2-4fa0-853d-ca443b4a4da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter the subject folder for the required day:  G:\\STREAM\\project_files\\Stream_HC_002_org\\10_11_23_n7_11_11_23_d\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Code block to reference the necessary folders\n",
    "\"\"\"\n",
    "parentfolder = input('enter the subject folder for the required day: ') \n",
    "\n",
    "\"\"\"\n",
    "names of folders to be used\n",
    "\"\"\"\n",
    "folder1 = 'empatica'\n",
    "folder2 = 'saved_figures'\n",
    "\n",
    "folder11 = 'aggr_p_min'\n",
    "folder12 = 'avro_files'\n",
    "folder13 = 'avro2csv'\n",
    "folder14 = 'preprocessed_files'\n",
    "folder141 = 'data_preproc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4949279d-dfa7-4e79-926a-991eda4565a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "now to extract scl and scr from raw data via flirt\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "now need function to one by one collect each raw avro file for a particular day, calculate eda fearures, get the mean of the columns tonic mean and phasic mean. These two measures for each day are to be collected in a dictionary. \n",
    "\"\"\"\n",
    "\n",
    "def give_means(file):\n",
    "    for file in os.listdir(ipfileDir):\n",
    "        if file.endswith('eda_cet.csv'):\n",
    "            df_eda_eplus = pd.read_csv(os.path.join(ipfileDir, file)) #filepath joining functionality \n",
    "            new_cet_index = pd.to_datetime(df_eda_eplus['CET_timestamp'])\n",
    "            df_eda_eplus.index = new_cet_index #indexing by date-time object to avoid error with flirt package\n",
    "            eda_feat_eplus = flirt.get_eda_features(df_eda_eplus['eda'],\n",
    "                                          window_length = 60, \n",
    "                                          window_step_size = 1,\n",
    "                                          data_frequency = 4)\n",
    "    return(eda_feat_eplus['tonic_mean'].mean(skipna=True), eda_feat_eplus['phasic_mean'].mean(skipna=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a11f775-78f0-485e-abfe-0bd18bcb7b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdde182576c743db90658c0728b23178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.48%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a797bc78d53d4532bd4493c130e961ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 74.59%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d1955bc1e14fccbd834f419ce21419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.5%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0027d1070b44da9a78c5367e88d11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 72.56%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d5160a93564c5a97f009109d27d873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.04%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a986a31e5204445b923e1cea3c4bcf6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 72.27%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1d0337cb714d2c95856be639e56581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 74.7%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf0813bc70c46bea0acce82745f43aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 74.25%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ba630ae338482fbee544eb982711f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/908 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 72.69%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373b0e73bf9a46d8bd0579bec9776243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.39%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2d0f9b65d141899f49292480ec6dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/908 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 74.12%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1d1bc4de9241e3bff7a2440d3b0fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.26%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3a8b9dd9c74e5e915902a239225a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 74.72%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0f1bc81eb548178563795fad169ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 75.42%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a79a6a675354778a8e7df221681513f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 72.49%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8359af60e04947d7ab267638adc711f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.98%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f03da03949d43f7854a58389586f6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 72.56%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4d2f4c34894895ad2c63bc128ce0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.27%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0cb308d4ea468d908cdf727b82f361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.89%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58392e50caf945c8979e10fe648991a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 72.33%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7caf814e794aa89cd882f86aa85a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 6.56%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 74.56%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39dc65f5da14fa588bebcf9f50cff24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.44%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98607b6d7754019976a05db02a5d5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 74.25%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6075c1a77a8a44458f61c81c1a5cf4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 75.33%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd45764d21e7433484f6d73f53603d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.26%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6df4938dca147949429dedea7b48acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/908 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.68%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455466473bcf4032bbf242de2bc36323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 74.05%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e736685291d6483cb7a11333217ee005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.31%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7926c335f9624e84a2d4dab554b5adc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 5.2%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 71.65%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a33b3b396184d1081a83bd1b893b905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.67%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f20e6b991b4b5eb92df1c331368373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.2%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712151d545fc4881b171ff1498a84848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 71.71%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8228fa258149f18de02775e611abc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/908 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 72.36%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb09cc582ec64f548e25c7572644168e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 7.11%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.0%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597e806f49244587871680db8649c106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.15%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7c74b679554a05a2e987b94e50d5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 72.71%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1473a968dce54e5cadc2043c082699fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 71.49%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22180f4577f64c659fbd6db2671797d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 5.97%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 74.48%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f6718c959f497583618e36179acc94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 72.98%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b0a3f82b49486b8e1b449cbd2f0c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 12.07%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 71.76%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ffc3e36ae5b4216aecdf4e935897875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 72.11%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c7b3628c454338954f6ab34c5d038c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 12.71%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 69.17%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17d2a9ddeec4654a17fe9239b3f57cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/895 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.85%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a480e7cd8f64ffcba96a9123ce44f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 74.75%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f36a7c4d1784e9cb46b2b047cdd3d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 71.78%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4eb613e24e476f8b13930aba86adbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.39%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a21a58106446fabf6d719bfc90a568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 70.43%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144e0228c2b24026a1f18ffec5055c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 5.3%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 71.49%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f94308dcd947ef9b2abbe7e57a8838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 6.57%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 73.05%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da83515310b47a68dd09a9ecf557aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 72.71%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8aaef3d95a4add92ec30899dd16f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/895 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 75.42%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11582087fccc475984ecfaa51b4e76fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/908 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 70.93%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "110ca5fd76da43f0a60d3349e157e29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 70.94%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1354adfab145c5b7e0aa81b414cc85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 70.44%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d8e5613c87a4c0b8bbedf692c95ff4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 72.16%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57acf8fdd4e448bf9828cd9a580a85b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 71.78%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd0ce0961b5e4888a0e6b976b4e20081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 71.93%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ade4dfbfbce4a789068ed31bdeaf009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 71.44%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b160310b941a4017a70a361ae594698b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 70.56%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1ecebe2a414aafaddabd3a541659c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 7.09%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 71.87%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43d7ed81d704aad86e1b309848bda31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 9.17%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 70.5%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f344d29f72f849bcb1ed62f6a8d129e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/908 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 71.92%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39729c97464a4554b1e4c13523f2b35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 72.27%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4873b170474b62b52f07d1e10a23aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 6.44%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 70.33%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa4652cb575483fa687b23c620323dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 7.33%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 70.11%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978df4e9d22141b8a36a5ede2476dae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 91.49%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 40.99%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6a2a41e2cc4abe932ad21eddf78647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 47.29%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 49.94%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed118df0b2ab48d396a1cfff74a1b7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 63.89%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f066787266a7402e929eb3eaabdb88cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 70.87%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595b32443a8c4ca9afeca37f6ed9fa2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 67.62%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fcdfe6cfe443ed83d11b84d6f258fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 72.31%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a1fe738fb342189af16c73b9036341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/898 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 19.6%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 66.59%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ebd06ef72b4707b2086847d7b33a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 25.3%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 65.41%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7da95560d5a4875a8ffeb4d0b5e3651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 72.22%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540aff64eb2f4d659b662be80e7770ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 69.89%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8f690fc7404b73afe480dc6a65d32e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/905 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 6.63%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 74.14%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730644f2b1314bd3a4984c43cad08956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 6.76%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 72.43%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74b7ca8c5ba4a219236ad7d773cd011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/900 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 6.44%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 65.78%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46e4919ff834993848ecd48dc853dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EDA features:   0%|          | 0/903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to remove memmapped file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: tonic_entropy contains more than 5% (actual: 6.64%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n",
      "C:\\Users\\Ananya Rao\\AppData\\Local\\Temp\\ipykernel_24796\\2635354578.py:7: UserWarning: phasic_entropy contains more than 5% (actual: 72.31%) nan, inf, or -inf values. We recommend to delete this feature column.\n",
      "  scl_mean, scr_mean = give_means(ipfileDir)\n"
     ]
    }
   ],
   "source": [
    "scl_mean_list = []\n",
    "scr_mean_list = []\n",
    "\n",
    "\n",
    "for folder in os.listdir(os.path.join(parentfolder, folder1, folder13)):\n",
    "    ipfileDir = os.path.join(parentfolder, folder1, folder13, folder)\n",
    "    scl_mean, scr_mean = give_means(ipfileDir)\n",
    "    scl_mean_list.append(scl_mean)\n",
    "    scr_mean_list.append(scr_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df6be47-af83-422e-b883-d3d7807850a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "code block to store the scl and scr lists as numpy arrays \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e247375e-6369-4a92-8095-5d8a0527b386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nincorporating alternate code for scl and scr preproc\\nCode developed as mentioned below:\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "incorporating alternate code for scl and scr preproc\n",
    "Code developed as mentioned in the cell below:\n",
    "Further adaptations to suit the purpose of the pipeline made by Ananya Ananth Rao ananyaananthrao@gmail.com\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb308402-8c3b-4636-9e0a-a0b6706070eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This is an adaptation of the EDA Explorer available at: https://github.com/MITMediaLabAffectiveComputing/eda-explorer/blob/master/EDA-Artifact-Detection-Script.py\n",
    "Taylor, S., Jaques, N., Chen, W., Fedor, S., Sano, A., and Picard, R. \"Automatic Identification of Artifacts in Electrodermal Activity Data\" In EMBC, August 2015.\n",
    "\n",
    "The adaptations of the script were made by Irene Sophia Plank, 10planki@gmail.com\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as scisig\n",
    "import pywt\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "matplotlib.rcParams['ps.useafm'] = True\n",
    "matplotlib.rcParams['pdf.use14corefonts'] = True\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "\n",
    "def predict_binary_classifier(X):\n",
    "    ''''\n",
    "    X: num test data by 13 features\n",
    "    '''\n",
    "\n",
    "    # Get params\n",
    "    params = binary_classifier()\n",
    "\n",
    "    # compute kernel for all data points\n",
    "    K = rbf_kernel(params['support_vec'], X, gamma=params['gamma'])\n",
    "\n",
    "    # Prediction = sign((sum_{i=1}^n y_i*alpha*K(x_i,x)) + rho)\n",
    "    predictions = np.zeros(X.shape[0])\n",
    "    for i in range(X.shape[0]):\n",
    "        # prediction is calculated and then divided into positive (no artefact) or negative (artefact)\n",
    "        predictions[i] = np.sign(np.sum(params['dual_coef']*K[:, i]) + params['intercept'])\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def binary_classifier():\n",
    "    gamma = 0.1\n",
    "\n",
    "    # dual coef = y_i*alpha_i\n",
    "    dual_coef = np.array([[-1.12775599e+02,  -1.00000000e+03,  -1.00000000e+03,\n",
    "                           -1.00000000e+03,  -1.00000000e+03,  -1.00000000e+03,\n",
    "                           -1.00000000e+03,  -1.00000000e+03,  -1.00000000e+03,\n",
    "                           -1.00000000e+03,  -1.00000000e+03,  -1.00000000e+03,\n",
    "                           -4.65947457e+02,  -1.00000000e+03,  -1.00000000e+03,\n",
    "                           -1.00000000e+03,  -1.17935400e+02,  -1.00000000e+03,\n",
    "                           -1.00000000e+03,  -1.00000000e+03,  -1.00000000e+03,\n",
    "                           -1.00000000e+03,  -1.00000000e+03,  -1.00000000e+03,\n",
    "                           -1.00000000e+03,  -2.92534132e+02,  -1.00000000e+03,\n",
    "                           -1.00000000e+03,  -3.69965631e+01,  -1.00000000e+03,\n",
    "                           -1.00000000e+03,  -1.00000000e+03,  -1.00000000e+03,\n",
    "                           -1.00000000e+03,  -1.00000000e+03,  -1.00000000e+03,\n",
    "                           -1.00000000e+03,  -1.00000000e+03,   1.00000000e+03,\n",
    "                           1.00000000e+03,   1.00000000e+03,   1.00000000e+03,\n",
    "                           7.92366387e+02,   3.00553142e+02,   2.22950860e-01,\n",
    "                           1.00000000e+03,   1.00000000e+03,   5.58636056e+02,\n",
    "                           1.21751544e+02,   1.00000000e+03,   1.00000000e+03,\n",
    "                           2.61920652e+00,   9.96570403e+02,   1.00000000e+03,\n",
    "                           1.00000000e+03,   1.00000000e+03,   1.00000000e+03,\n",
    "                           1.00000000e+03,   1.00000000e+03,   1.02270060e+02,\n",
    "                           5.41288840e+01,   1.91650287e+02,   1.00000000e+03,\n",
    "                           1.00000000e+03,   1.00000000e+03,   1.00000000e+03,\n",
    "                           1.00000000e+03,   2.45152637e+02,   7.53766346e+02,\n",
    "                           1.00000000e+03,   1.00000000e+03,   3.63211198e+00,\n",
    "                           1.00000000e+03,   3.31675798e+01,   5.64620367e+02,\n",
    "                           1.00000000e+03,   1.00000000e+03,   1.00000000e+03,\n",
    "                           2.66900636e+02,   1.00000000e+03,   6.54763900e+02,\n",
    "                           3.38216549e+02,   6.86434772e+01,   2.78998678e+02,\n",
    "                           6.97557950e+02,   1.00000000e+03]])\n",
    "\n",
    "    # intercept = rho\n",
    "    intercept = np.array([-2.63232929])\n",
    "\n",
    "    # support vectors = x_i\n",
    "    support_vec = np.array([[0.02809756, 0.0455, 0.025, 0.00866667, 0.03799132, -0.00799413, 0.01061208, 0.016263, 0.00671743, 0.00572262, 0.00578504, 0.00542415, 0.00318195],\n",
    "                            [0.00060976, 0.0035, 0.007, 0.00087179, 0.00024191, -0.0005069, 0.0005069, 0.0070711, 0.00306413, 0.0031833, 0.0107827, 0.0066959, 0.0022981],\n",
    "                            [3.49731707, 0.092, 0.054, 0.01923077, 3.53815367, -0.02236652, 0.02659884, 0.062225, 0.0316782, 0.01818914, 0.06607571, 0.03342241, 0.099702],\n",
    "                            [2.52643902, 0.058, 0.055, 0.0114359, 2.54031008, -0.01070662, 0.01296803, 0.043134, 0.01649923, 0.01579683, 0.03326171, 0.05004163, 0.013965],\n",
    "                            [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, -2.74622599e-18, -2.42947453e-17, 3.36047450e-17, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
    "                            [3.89758537, 0.167, 0.27, 0.06717949, 3.87923565, -0.04130143, 0.05403825, 0.047376, 0.0328098, 0.01255584, 0.03676955, 0.14237773, 0.11031],\n",
    "                            [0.93326829, 0.0855, 0.106, 0.01169231, 0.92669874, -0.02740927, 0.02740927, 0.043841, 0.01131377, 0.01595008, 0.0231871, 0.02414775, 0.0139655],\n",
    "                            [4.64253659, 0.106, 0.13, 0.03661538, 4.63806066, -0.03168223, 0.03168223, 0.10182, 0.0559785, 0.03369301, 0.06341563, 0.08583294, 0.0251025],\n",
    "                            [0.29312195, 0.028, 0.039, 0.00682051, 0.28575076, -0.00648365, 0.00648365, 0.0056569, 0.00367694, 0.00126494, 0.00364005, 0.01814984, 0.006364],\n",
    "                            [3.08187805, 0.0615, 0.123, 0.03435897, 3.11862292, -0.02260403, 0.02260403, 0.053033, 0.0397394, 0.01570345, 0.0338851, 0.10069204, 0.16652],\n",
    "                            [2.43902439e-05, 5.00000000e-04, 1.00000000e-03, 1.02564103e-04, 2.43769719e-05, -7.19856842e-05, 7.19856842e-05, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
    "                            [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, -4.05052739e-10, -2.77557303e-09, 5.77955577e-09, 7.07110000e-04, 1.17851667e-04, 2.88676449e-04, 2.04124145e-04, 1.44336183e-04, 0.00000000e+00],\n",
    "                            [0.83290244, 0.099, 0.172, 0.02610256, 0.82408369, -0.0168393, 0.0168393, 0.13011, 0.02875613, 0.04987211, 0.03786379, 0.02684837, 0.0155565],\n",
    "                            [0.92597561, 0.017, 0.009, 0.00369231, 0.92583814, -0.00670974, 0.00670974, 0.012021, 0.00506763, 0.00420523, 0.01259266, 0.0115391, 0.00265165],\n",
    "                            [2.43902439e-05, 5.00000000e-04, 1.00000000e-03, 2.56410256e-05, 2.18000765e-04, -5.56411248e-04, 5.56411248e-04, 9.19240000e-03, 2.71058333e-03, 4.25246049e-03, 2.49833278e-03, 7.64311464e-03, 0.00000000e+00],\n",
    "                            [0.88760976, 0.0205, 0.022, 0.00489744, 0.88799505, -0.00346772, 0.00461828, 0.011314, 0.00447838, 0.00394135, 0.01327278, 0.01434142, 0.00406585],\n",
    "                            [9.21263415, 0.118, 0.472, 0.0695641, 9.19153391, -0.02181738, 0.02181738, 0.16688, 0.07130037, 0.06135461, 0.04328934, 0.04277416, 0.0829085],\n",
    "                            [0.48378049, 0.017, 0.026, 0.00794872, 0.48333175, -0.00337375, 0.00350864, 0.016971, 0.0089568, 0.00472601, 0.01168189, 0.01629524, 0.0226275],\n",
    "                            [0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 9.65026603e-122, -2.00921455e-120, 4.22507597e-120, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
    "                            [0.10897561, 0.03, 0.033, 0.00553846, 0.12761266, -0.00442938, 0.00556735, 0.025456, 0.00872107, 0.00870258, 0.01130487, 0.01554551, 0.0123745],\n",
    "                            [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, -1.38812548e-09, -2.34438020e-08, 2.34438020e-08, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
    "                            [0.66663415, 0.052, 0.05, 0.00510256, 0.66182973, -0.01361869, 0.01361869, 0.0049497, 0.00296982, 0.00208565, 0.00424264, 0.00961131, 0.012374],\n",
    "                            [3.74146341e+00, 6.60000000e-02, 7.00000000e-02, 2.41025641e-02, 3.72790310e+00, -1.65194036e-02, 1.65194036e-02, 2.33350000e-02, 2.29102000e-02, 3.87787571e-04, 7.25086202e-03, 8.04828002e-03, 2.26270000e-02],\n",
    "                            [2.43902439e-05, 5.00000000e-04, 1.00000000e-03, 1.02564103e-04, 2.44149661e-05, -7.19856850e-05, 7.19856850e-05, 7.07110000e-04, 1.17851667e-04, 2.88676449e-04, 2.04124145e-04, 1.44336183e-04, 0.00000000e+00],\n",
    "                            [1.14713659e+01, 1.68000000e-01, 3.24000000e-01, 8.83589744e-02, 1.13977278e+01, -4.35202063e-02, 4.35202063e-02, 1.20920000e-01, 1.15826000e-01, 5.32593935e-03, 4.29825546e-02, 1.11681949e-01, 1.82080000e-01],\n",
    "                            [1.63631707, 0.0825, 0.138, 0.02410256, 1.65473267, -0.02914746, 0.02927458, 0.074953, 0.02899134, 0.03271076, 0.02718317, 0.09610564, 0.012728],\n",
    "                            [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.01460518e-42, -2.71490067e-40, 2.71490067e-40, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
    "                            [0.52358537, 0.038, 0.03, 0.00769231, 0.52319376, -0.01066405, 0.01066405, 0.026163, 0.01025307, 0.00912966, 0.02678697, 0.04011893, 0.00866185],\n",
    "                            [0.10931707, 0.103, 0.407, 0.04461538, 0.13188551, -0.01686662, 0.02506229, 0.1492, 0.0384195, 0.06327203, 0.06411448, 0.05508901, 0],\n",
    "                            [0.0444878, 0.0245, 0.04, 0.00984615, 0.03577326, -0.00573919, 0.00573919, 0.013435, 0.0078961, 0.00418135, 0.01136515, 0.01291603, 0.0134352],\n",
    "                            [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.03127202e-08, -2.56175141e-07, 5.37317466e-07, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
    "                            [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "                            [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.27917545e-05, -7.79437718e-04, 7.79437718e-04, 3.04060000e-02, 5.06766667e-03, 1.24131975e-02, 1.34721936e-02, 5.34029589e-02, 0.00000000e+00],\n",
    "                            [2.43902439e-05, 5.00000000e-04, 1.00000000e-03, 1.02564103e-04, 2.60691650e-05, -7.19856850e-05, 7.19856850e-05, 7.07110000e-04, 1.17851667e-04, 2.88676449e-04, 2.04124145e-04, 1.44336183e-04, 0.00000000e+00],\n",
    "                            [0.46446341, 0.033, 0.03, 0.00933333, 0.46299034, -0.00866364, 0.00866364, 0.033941, 0.01357644, 0.01214903, 0.02164486, 0.02701617, 0.012374],\n",
    "                            [5.89978049, 0.117, 0.112, 0.04453846, 5.88525247, -0.02253416, 0.02253416, 0.084146, 0.0492146, 0.01985341, 0.06802812, 0.09041259, 0.045255],\n",
    "                            [0.01317073, 0.0195, 0.015, 0.00538462, 0.00829287, -0.00622806, 0.00622806, 0.026163, 0.01145514, 0.00926554, 0.00690652, 0.02540613, 0.018031],\n",
    "                            [1.16509756, 0.028, 0.02, 0.01051282, 1.16338281, -0.01379371, 0.01379371, 0.020506, 0.01461345, 0.00563317, 0.01416569, 0.01971055, 0.0281075],\n",
    "                            [3.67914634, 0.1235, 0.126, 0.02676923, 3.67052968, -0.04266586, 0.04266586, 0.041719, 0.0233342, 0.0106888, 0.03232337, 0.07260248, 0.050912],\n",
    "                            [0.11331707, 0.0015, 0.004, 0.0014359, 0.11329803, -0.00042144, 0.00042144, 0.0021213, 0.0014142, 0.00109543, 0.00124164, 0.00053231, 0.00070713],\n",
    "                            [1.11256098, 0.026, 0.016, 0.00561538, 1.09093248, -0.00174647, 0.00490015, 0.02192, 0.01272782, 0.00816993, 0.02111102, 0.04921207, 0.012021],\n",
    "                            [0.06846341, 0.007, 0.01, 0.00307692, 0.06774886, -0.00179795, 0.00190969, 0.0056569, 0.00311126, 0.00162791, 0.00195576, 0.00721732, 0.01096],\n",
    "                            [1.16454634e+01, 1.78500000e-01, 3.20000000e-01, 8.94615385e-02, 1.15869935e+01, -1.15451745e-02, 1.59897956e-02, 1.37890000e-01, 1.23393333e-01, 1.01170444e-02, 3.66151153e-02, 1.46607419e-01, 1.94455000e-01],\n",
    "                            [3.45158537, 0.1375, 0.052, 0.01676923, 3.44594643, -0.03141983, 0.03141983, 0.038184, 0.0272946, 0.00958649, 0.01698014, 0.06290749, 0.1393],\n",
    "                            [3.12563415, 0.0535, 0.111, 0.02897436, 3.17337638, -0.02835417, 0.02835417, 0.054447, 0.0278601, 0.0188188, 0.00755315, 0.03628251, 0.055154],\n",
    "                            [8.50975610e-02, 1.00000000e-03, 4.00000000e-03, 8.20512821e-04, 8.50491997e-02, -1.84870042e-04, 2.35933619e-04, 1.41420000e-03, 1.41420000e-03, 2.60312573e-11, 4.08248290e-04, 2.88668284e-04, 7.07110000e-04],\n",
    "                            [0.82373171, 0.048, 0.121, 0.01853846, 0.82149219, -0.0053288, 0.00684639, 0.041012, 0.0208598, 0.01423898, 0.02609294, 0.02676908, 0.01078335],\n",
    "                            [4.39680488, 0.223, 0.354, 0.09258974, 4.35973108, -0.03206468, 0.03450864, 0.20506, 0.0971572, 0.07235446, 0.13713059, 0.23019854, 0.32138],\n",
    "                            [5.66058537, 0.0285, 0.093, 0.01282051, 5.66682734, -0.00633008, 0.00633008, 0.040305, 0.01513214, 0.01889847, 0.01503912, 0.03383458, 0],\n",
    "                            [0.13329268, 0.011, 0.021, 0.00338462, 0.13419267, -0.00262455, 0.00262455, 0.0035355, 0.00226272, 0.00092195, 0.00772172, 0.00411547, 0.0038891],\n",
    "                            [0.15463415, 0.0325, 0.065, 0.01617949, 0.15422134, -0.00766504, 0.00766504, 0.067882, 0.02286322, 0.02270081, 0.02939288, 0.0224428, 0.017501],\n",
    "                            [1.47902439e-01, 1.50000000e-03, 2.00000000e-03, 3.84615385e-04, 1.48269290e-01, -1.36058722e-04, 1.36058722e-04, 2.12130000e-03, 8.24950000e-04, 9.39849132e-04, 5.16397779e-04, 5.91603500e-04, 0.00000000e+00],\n",
    "                            [2.76797561, 0.071, 0.17, 0.03212821, 2.84223399, -0.01692731, 0.01692731, 0.04879, 0.03441267, 0.00934515, 0.03221283, 0.05768286, 0.092806],\n",
    "                            [1.30939024, 0.044, 0.066, 0.0165641, 1.2967273, -0.01727205, 0.01727205, 0.03182, 0.01456652, 0.01056655, 0.00732632, 0.02987207, 0.038891],\n",
    "                            [0.0914878, 0.038, 0.028, 0.00364103, 0.08295897, -0.00877545, 0.00877545, 0.032527, 0.00648182, 0.01277828, 0.01289089, 0.01040763, 0.0042426],\n",
    "                            [0.13621951, 0.0015, 0.006, 0.00174359, 0.13689296, -0.00036169, 0.00040731, 0.0021213, 0.00153205, 0.00082663, 0.00058452, 0.00069522, 0.00088391],\n",
    "                            [0.05692683, 0.007, 0.006, 0.00189744, 0.05532006, -0.00145672, 0.00145672, 0.0056569, 0.00311126, 0.00184393, 0.00420714, 0.00465287, 0.0070711],\n",
    "                            [0.07460976, 0.002, 0.006, 0.00097436, 0.07430141, -0.00035004, 0.00038011, 0.0028284, 0.00113136, 0.0011832, 0.00070711, 0.0005916, 0.00070711],\n",
    "                            [0.04782927, 0.006, 0.011, 0.00353846, 0.04406202, -0.00232859, 0.00232859, 0.012021, 0.00438408, 0.00442728, 0.00363318, 0.00540593, 0.0091924],\n",
    "                            [4.443, 0.141, 0.076, 0.02310256, 4.40858239, -0.03710778, 0.03710778, 0.03182, 0.0271528, 0.00465324, 0.03506173, 0.07970664, 0.11278],\n",
    "                            [8.79678049, 0.057, 0.208, 0.04194872, 8.784878, -0.01132933, 0.01132933, 0.08061, 0.04695182, 0.039817, 0.0405623, 0.01937402, 0.033234],\n",
    "                            [2.58236585, 0.063, 0.128, 0.02112821, 2.5705713, -0.0079298, 0.01979542, 0.062225, 0.0309712, 0.02172778, 0.02949491, 0.02741888, 0.02687],\n",
    "                            [0.08992683, 0.0015, 0.006, 0.00030769, 0.09000535, -0.00020308, 0.00020308, 0.0021213, 0.00106065, 0.00116188, 0.0007746, 0.00086603, 0.00053035],\n",
    "                            [0.09085366, 0.0175, 0.037, 0.00694872, 0.09607742, -0.00456388, 0.00456388, 0.0098995, 0.00523258, 0.00310646, 0.01357571, 0.0133944, 0.0056569],\n",
    "                            [1.34473171, 0.0255, 0.022, 0.00953846, 1.37010789, -0.00558419, 0.00558419, 0.030406, 0.0134351, 0.00877511, 0.00929516, 0.03188089, 0.0265165],\n",
    "                            [0.14253659, 0.001, 0.004, 0.00097436, 0.14237889, -0.0002998, 0.0002998, 0.0014142, 0.0011785, 0.00057734, 0.0005164, 0.00069521, 0.00106066],\n",
    "                            [0.07617073, 0.001, 0.004, 0.00179487, 0.07597272, -0.00025949, 0.00025949, 0.0014142, 0.0011785, 0.00057734, 0.0005164, 0.00063245, 0.00070711],\n",
    "                            [0.28502439, 0.0025, 0.01, 0.00241026, 0.28596915, -0.000355, 0.000355, 0.12869, 0.02333393, 0.05162999, 0.0313152, 0.13233722, 0.0044194],\n",
    "                            [5.97658537, 0.0645, 0.106, 0.02925641, 5.95365623, -0.01454886, 0.01454886, 0.045962, 0.02913296, 0.02145587, 0.04602717, 0.06410626, 0.053033],\n",
    "                            [4.19787805, 0.0405, 0.072, 0.02764103, 4.21230508, -0.01456906, 0.01468492, 0.030406, 0.02206174, 0.01003006, 0.02031748, 0.03873656, 0.034295],\n",
    "                            [0.06904878, 0.0025, 0.005, 0.00117949, 0.06819891, -0.00023428, 0.00033805, 0.0035355, 0.00098994, 0.00154918, 0.001, 0.0007071, 0.00070711],\n",
    "                            [2.07410488e+01, 1.10000000e-02, 4.40000000e-02, 1.24102564e-02, 2.07288498e+01, -5.11402880e-02, 5.11402880e-02, 1.55560000e-02, 1.55560000e-02, 0.00000000e+00, 5.68037557e-03, 3.17543685e-03, 7.77820000e-03],\n",
    "                            [0.15141463, 0.0025, 0.008, 0.00161538, 0.15286961, -0.00066236, 0.00066236, 0.0049497, 0.0021213, 0.00180276, 0.00235584, 0.01268589, 0.0021213],\n",
    "                            [1.07970732, 0.0275, 0.046, 0.00725641, 1.0819483, -0.0025949, 0.00261392, 0.026163, 0.00754248, 0.00945165, 0.01400506, 0.00566908, 0.011137],\n",
    "                            [1.45278049e+00, 2.50000000e-02, 3.40000000e-02, 8.23076923e-03, 1.46401853e+00, -5.22375992e-03, 7.56803574e-03, 8.48530000e-03, 6.71755000e-03, 1.39641061e-03, 4.14024959e-03, 1.47976972e-02, 2.03295000e-02],\n",
    "                            [1.18829268e-01, 1.00000000e-03, 4.00000000e-03, 1.17948718e-03, 1.18657803e-01, -3.33958979e-04, 3.55599268e-04, 1.41420000e-03, 1.41420000e-03, 2.60312573e-11, 6.32455532e-04, 5.32284214e-04, 7.07110000e-04],\n",
    "                            [0.09217073, 0.0085, 0.007, 0.00258974, 0.07952256, -0.00104703, 0.00138337, 0.006364, 0.00466692, 0.00203719, 0.00509166, 0.01307342, 0.021213],\n",
    "                            [0.06936585, 0.0095, 0.015, 0.00394872, 0.06837444, -0.00205373, 0.00205373, 0.0084853, 0.00296984, 0.0030984, 0.00234521, 0.00419839, 0.0017678],\n",
    "                            [5.05807317, 0.049, 0.082, 0.02402564, 5.06327737, -0.01120311, 0.01120311, 0.031113, 0.0239, 0.01338272, 0.01117139, 0.04351642, 0.020506],\n",
    "                            [0.26421951, 0.04, 0.068, 0.00902564, 0.2587529, -0.01040894, 0.01040894, 0.025456, 0.01060666, 0.00890233, 0.01111643, 0.04563416, 0.011314],\n",
    "                            [3.59336585, 0.0575, 0.054, 0.02094872, 3.58195886, -0.01804095, 0.01838506, 0.043134, 0.0336584, 0.01240579, 0.01683523, 0.04717173, 0.038184],\n",
    "                            [1.29187805, 0.026, 0.016, 0.00689744, 1.27916244, -0.00322078, 0.00490015, 0.025456, 0.01032378, 0.00861112, 0.01863263, 0.0636921, 0.038537],\n",
    "                            [6.28670732, 0.1245, 0.127, 0.03102564, 6.35501978, -0.01747513, 0.02813757, 0.084146, 0.04690465, 0.0254467, 0.06541464, 0.18275149, 0.15008],\n",
    "                            [10.64578049, 0.079, 0.284, 0.04564103, 10.64447668, -0.01946271, 0.01947497, 0.10889, 0.04186, 0.05739752, 0.06891299, 0.05417812, 0.050205],\n",
    "                            [3.32470732, 0.092, 0.046, 0.01687179, 3.32977984, -0.02794509, 0.02794509, 0.072125, 0.0288498, 0.02428699, 0.06277798, 0.10343739, 0.061518],\n",
    "                            [0.07358537, 0.001, 0.004, 0.00153846, 0.0735262, -0.00027514, 0.00027514, 0.0014142, 0.0009428, 0.00073029, 0.00075277, 0.00053228, 0.00070711]])\n",
    "\n",
    "    return {'dual_coef': dual_coef,\n",
    "            'support_vec': support_vec,\n",
    "            'intercept': intercept,\n",
    "            'gamma': gamma}\n",
    "\n",
    "def interpolateDataTo8Hz(data,sample_rate): #interpolateDataTo8Hz(dict_data['eda'], (1/dict_data['eda']['sampRate'].iloc[0]))\n",
    "    if sample_rate<8:\n",
    "        # Upsample by linear interpolation\n",
    "        data = data.resample(\"125L\").mean()\n",
    "    else:\n",
    "        if sample_rate>8:\n",
    "            # Downsample\n",
    "            idx_range = list(range(0,len(data))) # TODO: double check this one\n",
    "            data = data.iloc[idx_range[0::int(int(sample_rate)/8)]]\n",
    "        # Set the index to be 8Hz\n",
    "        data.index = pd.timedelta_range(start='0S', periods=len(data), freq='125L')\n",
    "        #return data - RETURN STATEMENT 3 - ARRANGE THE APPROPRIATE RETURN STATMENT AT EDA_ARTIFACT_DETECTION_NOTAG AND PREPRO\n",
    "\n",
    "    # Interpolate all empty values\n",
    "    data = data.interpolate()\n",
    "    return data #- RETURN STATEMENT 4 - ARRANGE THE APPROPRIATE RETURN STATMENT AT EDA_ARTIFACT_DETECTION_NOTAG AND PREPRO\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    # Filtering Helper functions\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = scisig.butter(order, normal_cutoff, btype='low', analog=False) #therefore digital filter\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    # Filtering Helper functions\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = scisig.lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def getWaveletData(data):\n",
    "    '''\n",
    "    This function computes the wavelet coefficients\n",
    "\n",
    "    INPUT:\n",
    "        data:           DataFrame, index is a list of timestamps at 8Hz, columns include EDA, filtered_eda\n",
    "\n",
    "    OUTPUT:\n",
    "        wave1Second:    DateFrame, index is a list of timestamps at 1Hz, columns include OneSecond_feature1, OneSecond_feature2, OneSecond_feature3 \n",
    "        waveHalfSecond: DateFrame, index is a list of timestamps at 2Hz, columns include HalfSecond_feature1, HalfSecond_feature2 \n",
    "    '''\n",
    "    startTime = data.index[0]\n",
    "    print('from getWaveletData, starttime is: ', startTime, type(startTime)) #NOT RETURN STATEMENT BUT LOOK OUT\n",
    "\n",
    "    # Create wavelet dataframes\n",
    "    oneSecond = pd.date_range(start=startTime, periods=len(data), freq='1s')\n",
    "    halfSecond = pd.date_range(start=startTime, periods=len(data), freq='500L')\n",
    "    #oneSecond = pd.timedelta_range(start=startTime, periods=len(data), freq='1s') #OPTIONAL (NOT) RETURN STATEMENTS TO REPRODUCE ERRORS IF REQUIRED\n",
    "    #halfSecond = pd.timedelta_range(start=startTime, periods=len(data), freq='500L')\n",
    "\n",
    "    # Compute wavelets\n",
    "    cA_n, cD_3, cD_2, cD_1 = pywt.wavedec(data['eda'], 'Haar', level=3) #3 = 1Hz, 2 = 2Hz, 1=4Hz\n",
    "    \n",
    "    # Wavelet 1 second window\n",
    "    N = int(len(data)/8)\n",
    "    coeff1 = np.max(abs(np.reshape(cD_1[0:4*N],(N,4))), axis=1)\n",
    "    coeff2 = np.max(abs(np.reshape(cD_2[0:2*N],(N,2))), axis=1)\n",
    "    coeff3 = abs(cD_3[0:N])\n",
    "    wave1Second = pd.DataFrame({'OneSecond_feature1':coeff1,'OneSecond_feature2':coeff2,'OneSecond_feature3':coeff3})\n",
    "    wave1Second.index = oneSecond[:len(wave1Second)]\n",
    "    \n",
    "    # Wavelet Half second window\n",
    "    N = int(np.floor((len(data)/8.0)*2))\n",
    "    coeff1 = np.max(abs(np.reshape(cD_1[0:2*N],(N,2))),axis=1)\n",
    "    coeff2 = abs(cD_2[0:N])\n",
    "    waveHalfSecond = pd.DataFrame({'HalfSecond_feature1':coeff1,'HalfSecond_feature2':coeff2})\n",
    "    waveHalfSecond.index = halfSecond[:len(waveHalfSecond)]\n",
    "\n",
    "    return wave1Second,waveHalfSecond\n",
    "\n",
    "\n",
    "def getDerivatives(eda):\n",
    "    deriv = (eda[1:-1] + eda[2:])/ 2. - (eda[1:-1] + eda[:-2])/ 2.\n",
    "    second_deriv = eda[2:] - 2*eda[1:-1] + eda[:-2]\n",
    "    #put print statements under these\n",
    "    return deriv,second_deriv\n",
    "\n",
    "def getDerivStats(eda):\n",
    "    deriv, second_deriv = getDerivatives(eda)\n",
    "    maxd = max(deriv)\n",
    "    mind = min(deriv)\n",
    "    maxabsd = max(abs(deriv))\n",
    "    avgabsd = np.mean(abs(deriv))\n",
    "    max2d = max(second_deriv)\n",
    "    min2d = min(second_deriv)\n",
    "    maxabs2d = max(abs(second_deriv))\n",
    "    avgabs2d = np.mean(abs(second_deriv))\n",
    "    \n",
    "    return maxd,mind,maxabsd,avgabsd,max2d,min2d,maxabs2d,avgabs2d\n",
    "\n",
    "\n",
    "def getStats(data):\n",
    "    eda = data['eda'].values\n",
    "    filt = data['filtered_eda'].values\n",
    "    maxd,mind,maxabsd,avgabsd,max2d,min2d,maxabs2d,avgabs2d = getDerivStats(eda)\n",
    "    maxd_f,mind_f,maxabsd_f,avgabsd_f,max2d_f,min2d_f,maxabs2d_f,avgabs2d_f = getDerivStats(filt)\n",
    "    amp = np.mean(eda)\n",
    "    amp_f = np.mean(filt)\n",
    "    return amp, maxd,mind,maxabsd,avgabsd,max2d,min2d,maxabs2d,avgabs2d,amp_f,maxd_f,mind_f,maxabsd_f,avgabsd_f,max2d_f,min2d_f,maxabs2d_f,avgabs2d_f\n",
    "\n",
    "\n",
    "def computeWaveletFeatures(waveDF):\n",
    "    maxList = waveDF.max().tolist()\n",
    "    meanList = waveDF.mean().tolist()\n",
    "    stdList = waveDF.std().tolist()\n",
    "    medianList = waveDF.median().tolist()\n",
    "    aboveZeroList = (waveDF[waveDF>0]).count().tolist()\n",
    "\n",
    "    return maxList,meanList,stdList,medianList,aboveZeroList\n",
    "\n",
    "\n",
    "def getWavelet(wave1Second,waveHalfSecond):\n",
    "    max_1,mean_1,std_1,median_1,aboveZero_1 = computeWaveletFeatures(wave1Second)\n",
    "    max_H,mean_H,std_H,median_H,aboveZero_H = computeWaveletFeatures(waveHalfSecond)\n",
    "    return max_1,mean_1,std_1,median_1,aboveZero_1,max_H,mean_H,std_H,median_H,aboveZero_H\n",
    "\n",
    "\n",
    "def getFeatures(data,w1,wH):\n",
    "    # Get DerivStats\n",
    "    amp,maxd,mind,maxabsd,avgabsd,max2d,min2d,maxabs2d,avgabs2d,amp_f,maxd_f,mind_f,maxabsd_f,avgabsd_f,max2d_f,min2d_f,maxabs2d_f,avgabs2d_f = getStats(data)\n",
    "    statFeat = np.hstack([amp,maxd,mind,maxabsd,avgabsd,max2d,min2d,maxabs2d,avgabs2d,amp_f,maxd_f,mind_f,maxabsd_f,avgabsd_f,max2d_f,min2d_f,maxabs2d_f,avgabs2d_f])\n",
    "\n",
    "    # Get Wavelet Features\n",
    "    max_1,mean_1,std_1,median_1,aboveZero_1,max_H,mean_H,std_H,median_H,aboveZero_H = getWavelet(w1,wH)\n",
    "    waveletFeat = np.hstack([max_1,mean_1,std_1,median_1,aboveZero_1,max_H,mean_H,std_H,median_H,aboveZero_H])\n",
    "\n",
    "    all_feat = np.hstack([statFeat,waveletFeat])\n",
    "    \n",
    "    if np.Inf in all_feat:\n",
    "        print(\"Inf\")\n",
    "    \n",
    "    if np.NaN in all_feat:\n",
    "        print(\"NaN\")\n",
    "\n",
    "    return list(all_feat)\n",
    "\n",
    "\n",
    "def createFeatureDF(data):\n",
    "    '''\n",
    "    INPUTS:\n",
    "        filepath:           string, path to input file  \n",
    "    OUTPUTS:\n",
    "        features:           DataFrame, index is a list of timestamps for each 5 seconds, contains all the features\n",
    "        data:               DataFrame, index is a list of timestamps at 8Hz, columns include eda, filtered_eda\n",
    "    '''\n",
    "    # Load data from q sensor\n",
    "    wave1sec,waveHalf = getWaveletData(data)\n",
    "    \n",
    "    # Create 5 second timestamp list\n",
    "    timestampList = data.index.tolist()[0::40]\n",
    "    \n",
    "    # feature names for DataFrame columns\n",
    "    allFeatureNames = ['raw_amp','raw_maxd','raw_mind','raw_maxabsd','raw_avgabsd','raw_max2d','raw_min2d','raw_maxabs2d','raw_avgabs2d','filt_amp','filt_maxd','filt_mind',\n",
    "        'filt_maxabsd','filt_avgabsd','filt_max2d','filt_min2d','filt_maxabs2d','filt_avgabs2d','max_1s_1','max_1s_2','max_1s_3','mean_1s_1','mean_1s_2','mean_1s_3',\n",
    "        'std_1s_1','std_1s_2','std_1s_3','median_1s_1','median_1s_2','median_1s_3','aboveZero_1s_1','aboveZero_1s_2','aboveZero_1s_3','max_Hs_1','max_Hs_2','mean_Hs_1',\n",
    "        'mean_Hs_2','std_Hs_1','std_Hs_2','median_Hs_1','median_Hs_2','aboveZero_Hs_1','aboveZero_Hs_2']\n",
    "\n",
    "    # Initialize Feature Data Frame\n",
    "    features = pd.DataFrame(np.zeros((len(timestampList),len(allFeatureNames))),columns=allFeatureNames,index=timestampList)\n",
    "    \n",
    "    # Compute features for each 5 second epoch\n",
    "    for i in range(len(features)-1):\n",
    "        start = features.index[i]\n",
    "        end = features.index[i+1]\n",
    "        this_data = data[start:end]\n",
    "        this_w1 = wave1sec[start:end]\n",
    "        this_w2 = waveHalf[start:end]\n",
    "        features.iloc[i] = getFeatures(this_data,this_w1,this_w2)\n",
    "    return features\n",
    "\n",
    "\n",
    "def classifyEpochs(features,featureNames,classifierName):\n",
    "    '''\n",
    "    This function takes the full features DataFrame and classifies each 5 second epoch into artifact, questionable, or clean\n",
    "\n",
    "    INPUTS:\n",
    "        features:           DataFrame, index is a list of timestamps for each 5 seconds, contains all the features\n",
    "        featureNames:       list of Strings, subset of feature names needed for classification\n",
    "        classifierName:     string, type of SVM (binary or multiclass)\n",
    "\n",
    "    OUTPUTS:\n",
    "        labels:             Series, index is a list of timestamps for each 5 seconds, values of -1, 0, or 1 for artifact, questionable, or clean\n",
    "    '''\n",
    "    # Only get relevant features\n",
    "    features = features[featureNames]\n",
    "    X = features[featureNames].values\n",
    "\n",
    "    # Classify each 5 second epoch and put into DataFrame\n",
    "    featuresLabels = predict_binary_classifier(X)\n",
    "    \n",
    "    return featuresLabels\n",
    "\n",
    "\n",
    "def getSVMFeatures(key):\n",
    "    '''\n",
    "    This returns the list of relevant features\n",
    "\n",
    "    INPUT:\n",
    "        key:                string, either \"Binary\" or \"Multiclass\"\n",
    "\n",
    "    OUTPUT:\n",
    "        featureList:        list of Strings, subset of feature names needed for classification\n",
    "    '''\n",
    "    if key == \"Binary\":\n",
    "        return ['raw_amp','raw_maxabsd','raw_max2d','raw_avgabs2d','filt_amp','filt_min2d','filt_maxabs2d','max_1s_1',\n",
    "                                'mean_1s_1','std_1s_1','std_1s_2','std_1s_3','median_1s_3']\n",
    "    elif key == \"Multiclass\":\n",
    "        return ['filt_maxabs2d','filt_min2d','std_1s_1','raw_max2d','raw_amp','max_1s_1','raw_maxabs2d','raw_avgabs2d',\n",
    "                                    'filt_max2d','filt_amp']\n",
    "    else:\n",
    "        print('Error!! Invalid key, choose \"Binary\" or \"Multiclass\"\\n\\n')\n",
    "        return\n",
    "\n",
    "\n",
    "def classify(data):\n",
    "    '''\n",
    "    This function wraps other functions in order to load, classify, and return the label for each 5 second epoch of Q sensor data.\n",
    "\n",
    "    INPUT:\n",
    "        data\n",
    "    OUTPUT:\n",
    "        featureLabels:          Series, index is a list of timestamps for each 5 seconds, values of -1, 0, or 1 for artifact, questionable, or clean\n",
    "        data:                   DataFrame, only output if fullFeatureOutput=1, index is a list of timestamps at 8Hz, columns include eda, filtered_eda\n",
    "    '''\n",
    "    \n",
    "    # Get correct feature names for classifier\n",
    "    classifierName = 'Binary'\n",
    "\n",
    "    # Get pickle List and featureNames list\n",
    "    featureNames = getSVMFeatures(classifierName)\n",
    "\n",
    "    # Create the feature array and then apply the classifier    \n",
    "    features = createFeatureDF(data)\n",
    "    labels   = classifyEpochs(features, featureNames, classifierName)\n",
    "\n",
    "    return labels, data\n",
    "\n",
    "def plotData_notag(data, labels, filepath, subject, tag, filteredPlot=0, secondsPlot=0): #maybe change filteredPlot to 1, plotData_notag(data, labels, dir_out, subject, tag, 1, 0)\n",
    "    '''\n",
    "    This function plots the Q sensor EDA data with shading for artifact (red) and questionable data (grey). \n",
    "        Note that questionable data will only appear if you choose a multiclass classifier\n",
    "\n",
    "    INPUT:\n",
    "        data:                   DataFrame, indexed by timestamps at 8Hz, columns include EDA and filtered_eda\n",
    "        labels:                 array, each row is a 5 second period and each column is a different classifier\n",
    "        filteredPlot:           binary, 1 for including filtered EDA in plot, 0 for only raw EDA on the plot, defaults to 0\n",
    "        secondsPlot:            binary, 1 for x-axis in seconds, 0 for x-axis in minutes, defaults to 0\n",
    "\n",
    "    OUTPUT:\n",
    "        [plot]                  the resulting plot has N subplots (where N is the length of classifierList) that have linked x and y axes \n",
    "                                    and have shading for artifact (red) and questionable data (grey)\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # Initialize x axis\n",
    "    if secondsPlot:\n",
    "        scale = 1.0\n",
    "    else:\n",
    "        scale = 60.0\n",
    "    time_m = np.arange(0,len(data))/(8.0*scale)\n",
    "    \n",
    "    # Initialize Figure\n",
    "    plt.figure(figsize=(10,5))\n",
    "\n",
    "    # For each classifier, label each epoch and plot\n",
    "    key = 'Binary'\n",
    "        \n",
    "    # Initialize Subplots\n",
    "    ax = plt.subplot(1,1,1)\n",
    "\n",
    "    # Plot EDA\n",
    "    ax.plot(time_m,data['eda'], c='b', label ='Raw SC')\n",
    "\n",
    "    # For each epoch, shade if necessary\n",
    "    for i in range(0,len(labels)-1):\n",
    "        if labels[i]==-1:\n",
    "            # artifact\n",
    "            start = i*40/(8.0*scale)\n",
    "            end = start+5.0/scale\n",
    "            ax.axvspan(start, end, facecolor='red', alpha=0.7, edgecolor ='none', label = 'artifact') #better to give this a label so that in legend it doesn't keep getting incorrectly labelled as filtered data\n",
    "        elif labels[i]==0:\n",
    "            # Questionable\n",
    "            start = i*40/(8.0*scale)\n",
    "            end = start+5.0/scale\n",
    "            ax.axvspan(start, end, facecolor='.5', alpha=0.5,edgecolor ='none', label = 'questionable')\n",
    "\n",
    "    # Plot filtered data if requested\n",
    "    if filteredPlot:\n",
    "        ax.plot(time_m-.625/scale,data['filtered_eda'], c='g', linestyle='--', label = 'Filtered SC') #maybe make this dashed line so that the underlying raw data in blue can still be seen because now the raw data is being completely covered.\n",
    "        plt.legend(['Raw SC','Filtered SC', 'Artifact'],loc=0)\n",
    "    else:\n",
    "        plt.legend(['Raw SC', 'Artifact'],loc=0)\n",
    "\n",
    "    # Label and Title each subplot\n",
    "    plt.ylabel('$\\mu$S')\n",
    "    plt.title(key)\n",
    "    \n",
    "    # Only include x axis label on final subplot\n",
    "    if secondsPlot:\n",
    "        plt.xlabel('Time (s)')    \n",
    "    else:\n",
    "        plt.xlabel('Time (min)')\n",
    "\n",
    "    # Display the plot\n",
    "    plt.subplots_adjust(hspace=.3)\n",
    "    plt.show()\n",
    "    plt.savefig(os.path.join(filepath, subject + '_' + tag + '_artefacts.png'), dpi = 300) #take out the exp after experimenting is done\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "\n",
    "def EDA_artifact_detection_notag(dict_data, dir_out, subject, tag):\n",
    "    \n",
    "    # make sure data has 8Hz\n",
    "    data = interpolateDataTo8Hz(dict_data['eda'], (1/dict_data['eda']['sampRate'].iloc[0])) #interpolateDataTo8Hz(dict_df['eda'], (1/dict_df['sampRate'].iloc[0]))#data  = interpolateDataTo8Hz(dict_df['eda'], (1/dict_df['eda']['sampRate'].iloc[0]))\n",
    "    \n",
    "    # forward propagate data to fill NAs after merging\n",
    "    data = data.ffill()\n",
    "    #return data\n",
    "    \n",
    "    \n",
    "    # get the filtered data using a low-pass butterworth filter (cutoff:1hz, fs:8hz, order:6)\n",
    "    data['filtered_eda'] =  butter_lowpass_filter(data['eda'], 1.0, 8, 6) #butter_lowpass_filter(data, 1.0, 8, 6) #butter_lowpass_filter(data['eda'], 1.0, 8, 6)\n",
    "    #return data - RETURN STATEMENT 5 (TO SEE WHAT THE FILTERED EDA COLUMN LOOKS LIKE) - ARRANGE RETURNS IN OUTER FUNCTIONS ACCORDINGLY    \n",
    "    \n",
    "    \n",
    "    # classify the data\n",
    "    labels, data = classify(data)\n",
    "\n",
    "    # plot data\n",
    "    plotData_notag(data, labels, dir_out, subject, tag, 1, 0)   #change the second last entry back to 1 after experimenting is done - changed back\n",
    "\n",
    "    # save labels\n",
    "    fullOutputPath = os.path.join(dir_out, subject + '_' + tag + '_artefacts.csv')\n",
    "\n",
    "    #featureLabels = pd.DataFrame(labels, index=pd.timedelta_range(start=data.index[0], periods=len(labels), freq='5s'),\n",
    "                                 #columns=['Binary'])\n",
    "    featureLabels = pd.DataFrame(labels, index=pd.date_range(start=data.index[0], periods=len(labels), freq='5s'),\n",
    "                                 columns=['Binary'])\n",
    "\n",
    "    featureLabels.reset_index(inplace=True)\n",
    "    featureLabels.rename(columns={'index':'StartTime'}, inplace=True)\n",
    "    #featureLabels['EndTime'] = featureLabels['StartTime']+datetime.timedelta(seconds=5)\n",
    "    featureLabels['EndTime'] = featureLabels['StartTime']+timedelta(seconds=5)\n",
    "    featureLabels.index.name = 'EpochNum'\n",
    "\n",
    "    featureLabels.to_csv(fullOutputPath)\n",
    "    \n",
    "    return featureLabels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19fe600-6daa-4941-9b7a-2e577f130fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "\n",
    "This is a preprocessing pipeline for psychophysiological data collected with \n",
    "Empatica wristbands, either E4 or E+. It uses EDA Explorer to detect \n",
    "artefacts in the data based on EDA, temperature and acceleration data using\n",
    "a binary classifier (noise versus okay). For the preprocessing, it uses \n",
    "functions from the NeuroKit2 package. Specifically for the EDA preprocessing, \n",
    "it also draws inspiration from Ledalab. \n",
    "\n",
    "Arguments: \n",
    "    empatica   : either 'e4' or 'e+' or 'cut' (4Hz EDA and 64Hz BVP only)\n",
    "    winwidth   : width of the window for smoothing of EDA with Gaussian kernel (int)\n",
    "    lowpass    : lowpass filter frequency for EDA - has to be no larger than half the sample rate\n",
    "    dir_out    : output directory for all the results\n",
    "    dir_path   : input directory\n",
    "    exclude    : list of patterns to be excluded from preprocessing\n",
    "\n",
    "The function creates preprocessed data files for EDA and BVP as well as plots \n",
    "to check the data quality. \n",
    "\n",
    "(c) Irene Sophia Plank, 10planki@gmail.com\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# load all modules\n",
    "import neurokit2 as nk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import simple_colors\n",
    "import math\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "#warnings.simplefilter('ignore', UserWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from avro.datafile import DataFileReader\n",
    "from avro.io import DatumReader\n",
    "from datetime import datetime\n",
    "\n",
    "#added by me:\n",
    "from datetime import timedelta\n",
    "import pytz\n",
    "from pathlib import Path\n",
    "#from EDA_artifactdetection_short import EDA_artifact_detection\n",
    "\n",
    "###### Helper functions\n",
    "\n",
    "def gauss_smoothing(data, winwidth):\n",
    "    # Gaussian smoothing of EDA data\n",
    "    \n",
    "    # pad to remove border errors\n",
    "    fdata = pd.concat([pd.Series(data.iloc[0]), data, pd.Series(data.iloc[-1])])\n",
    "    \n",
    "    # ensure an even window width\n",
    "    winwidth = math.floor(winwidth/2)*2\n",
    "    \n",
    "    # extend data to reduce convolution error at beginning and end\n",
    "    data_ext = pd.concat([pd.Series([fdata.iloc[0]]*int(winwidth/2)), fdata, pd.Series([fdata.iloc[-1]]*int(winwidth/2))])\n",
    "    \n",
    "    # apply normpdf (?)\n",
    "    x = np.array(range(1, winwidth+2))\n",
    "    mu = winwidth/2+1\n",
    "    sigma = winwidth/8\n",
    "    window = np.exp(-0.5 * ((x - mu)/sigma)**2) / (math.sqrt(2*math.pi) * sigma)\n",
    "    window = window / sum(window)\n",
    "    \n",
    "    # perform convolution for smoothing\n",
    "    sdata_ext = np.convolve(data_ext, window)\n",
    "    \n",
    "    # cut to length of data\n",
    "    return sdata_ext[(1+winwidth):(len(sdata_ext)-winwidth-1)]\n",
    "\n",
    "def int_missing(df_eda, df_bvp, df_temp, df_acc, f):\n",
    "    # performing linear interpolation for bvp, temp and acc as well as cubic\n",
    "    # spline interpolation for eda\n",
    "    \n",
    "    # only process temp if it is not empty\n",
    "    if len(df_temp) > 0:\n",
    "        sampRate = df_temp['sampRate'].iloc[0]\n",
    "        df_temp = df_temp.interpolate()\n",
    "        df_temp = df_temp.bfill()\n",
    "        df_temp['sampRate'] = sampRate\n",
    "    \n",
    "    # only process acc if it is not empty\n",
    "    if len(df_acc) > 0:\n",
    "        sampRate = df_acc['sampRate'].iloc[0]\n",
    "        df_acc = df_acc.interpolate()\n",
    "        df_acc = df_acc.bfill()\n",
    "        df_acc['sampRate'] = sampRate\n",
    "    \n",
    "    # EDA\n",
    "    #sampRate = df_eda['sampRate'].iloc[0]  - commented out in this line and added below because the first sampRate value was turning up as NaN\n",
    "    raw    = df_eda['eda']\n",
    "    df_eda = df_eda.interpolate(method='spline', order=3)\n",
    "    df_eda = df_eda.bfill()\n",
    "    df_eda['raw'] = raw\n",
    "    sampRate = df_eda['sampRate'].iloc[0]\n",
    "    df_eda['sampRate'] = sampRate\n",
    "    \n",
    "    # BVP\n",
    "    sampRate = df_bvp['sampRate'].iloc[0]\n",
    "    raw    = df_bvp['bvp']\n",
    "    df_bvp = df_bvp.interpolate()\n",
    "    df_bvp = df_bvp.bfill()\n",
    "    df_bvp['raw'] = raw\n",
    "    df_bvp['sampRate'] = sampRate\n",
    "    \n",
    "    # print how much was interpolated for bvp and eda\n",
    "    per_eda = np.mean(raw.isna())\n",
    "    per_bvp = np.mean(raw.isna())\n",
    "    if round(per_eda, 2) == round(per_bvp, 2):\n",
    "        if per_eda >= 0.2:\n",
    "            print(simple_colors.red(datetime.now().strftime(\"%H:%M:%S\") + ' - ' + str(round(per_eda*100,2)) + ' percent of data were interpolated', 'bold'))\n",
    "        elif per_eda >= 0.01:\n",
    "            print(simple_colors.yellow(datetime.now().strftime(\"%H:%M:%S\") + ' - ' + str(round(per_eda*100,2)) + ' percent of data were interpolated', 'bold'))\n",
    "    else:\n",
    "        if per_eda >= 0.2:\n",
    "            print(simple_colors.red(datetime.now().strftime(\"%H:%M:%S\") + ' - ' + str(round(per_eda*100,2)) + ' percent EDA were interpolated', 'bold'))\n",
    "        elif per_eda >= 0.01:\n",
    "            print(simple_colors.yellow(datetime.now().strftime(\"%H:%M:%S\") + ' - ' + str(round(per_eda*100,2)) + ' percent EDA were interpolated', 'bold'))\n",
    "        if per_bvp >= 0.2:\n",
    "            print(simple_colors.red(datetime.now().strftime(\"%H:%M:%S\") + ' - ' + str(round(per_bvp*100,2)) + ' percent BVP were interpolated', 'bold'))\n",
    "        elif per_bvp >= 0.01:\n",
    "            print(simple_colors.yellow(datetime.now().strftime(\"%H:%M:%S\") + ' - ' + str(round(per_bvp*100,2)) + ' percent BVP were interpolated', 'bold'))\n",
    "    \n",
    "    # write to log file\n",
    "    f.write('\\n' + datetime.now().strftime(\"%H:%M:%S\") + ' - ' + str(round(per_bvp*100,2)) + '% BVP and ' + str(round(per_eda*100,2)) + '% EDA were interpolated')\n",
    "    \n",
    "    # return the dataframes\n",
    "    return df_eda, df_bvp, df_temp, df_acc\n",
    "\n",
    "def na_missing(df_eda, df_bvp, labels):\n",
    "    # taking the labels from the artefact detection classifier and create column\n",
    "    # with NaNs where artefacts were detected\n",
    "    \n",
    "    # join label dataframes with the dataframes containing EDA and BVP\n",
    "    labels.index = labels['StartTime']\n",
    "    df_eda = df_eda.join(labels, how='outer')\n",
    "    df_bvp = df_bvp.join(labels, how='outer')\n",
    "    \n",
    "    # fill up the NaNs with the preceeding label\n",
    "    df_eda['Binary'] = df_eda['Binary'].fillna(method='ffill')\n",
    "    df_bvp['Binary'] = df_bvp['Binary'].fillna(method='ffill')\n",
    "    \n",
    "    # calculate the new column and drop the unnecessary ones\n",
    "    df_eda['eda'] = np.where(df_eda['Binary'] == 1, df_eda['eda'], np.nan)\n",
    "    df_bvp['bvp'] = np.where(df_bvp['Binary'] == 1, df_bvp['bvp'], np.nan)\n",
    "    df_eda = df_eda.drop(columns=['StartTime', 'EndTime'])\n",
    "    df_bvp = df_bvp.drop(columns=['StartTime', 'EndTime'])\n",
    "    \n",
    "    return df_eda, df_bvp\n",
    "\n",
    "###### Cut and convert the data\n",
    "\n",
    "def read_avro(filepath, timezone = 'Europe/Berlin'):\n",
    "    # reading in avro data and converting it into data frames with the correct time stamp\n",
    "    \n",
    "    # read in the avro data\n",
    "    reader = DataFileReader(open(filepath, \"rb\"), DatumReader())\n",
    "    for user in reader:\n",
    "        dict_data = user\n",
    "    reader.close()\n",
    "\n",
    "    target_timezone = pytz.timezone(timezone) #change to required timezone if needed - done\n",
    "    # temperature: \n",
    "    startTime = datetime.utcfromtimestamp((float(dict_data['rawData']['temperature']['timestampStart'])/(10**(len(str(dict_data['rawData']['temperature']['timestampStart']))-10)))).replace(tzinfo=pytz.utc).astimezone(target_timezone) #1000000\n",
    "    #cet = pytz.timezone('Europe/Berlin') #me\n",
    "    #startTime = cet.localize(startTime) #me\n",
    "    sampRate  = dict_data['rawData']['temperature']['samplingFrequency']\n",
    "    df_temp   = pd.DataFrame(dict_data['rawData']['temperature']['values'], columns=[\"temp\"])\n",
    "    if sampRate > 0.0:\n",
    "        freq      = str(round(1/sampRate)) + 'S'\n",
    "        time      = pd.date_range(startTime, periods=len(df_temp), freq=freq)\n",
    "        df_temp.index = time\n",
    "        df_temp['sampRate'] = round(1/sampRate)\n",
    "    \n",
    "    # acceleration\n",
    "    startTime = datetime.utcfromtimestamp((float(dict_data['rawData']['accelerometer']['timestampStart'])/(10**(len(str(dict_data['rawData']['accelerometer']['timestampStart']))-10)))).replace(tzinfo=pytz.utc).astimezone(target_timezone)\n",
    "    #cet = pytz.timezone('Europe/Berlin') #me\n",
    "    #startTime = cet.localize(startTime) #me\n",
    "    sampRate  = dict_data['rawData']['accelerometer']['samplingFrequency']\n",
    "    df_acc    = pd.DataFrame({'accx_raw': dict_data['rawData']['accelerometer']['x'],\n",
    "                              'accy_raw': dict_data['rawData']['accelerometer']['y'],\n",
    "                              'accz_raw': dict_data['rawData']['accelerometer']['z']})\n",
    "    if sampRate > 0.0:\n",
    "        freq      = str(round(1/sampRate, 6)) + 'S'\n",
    "        time      = pd.date_range(startTime, periods=len(df_acc), freq=freq)\n",
    "        df_acc.index = time\n",
    "        df_acc['sampRate'] = round(1/sampRate, 6)\n",
    "    \n",
    "    # bvp\n",
    "    startTime = datetime.utcfromtimestamp((float(dict_data['rawData']['bvp']['timestampStart'])/(10**(len(str(dict_data['rawData']['bvp']['timestampStart']))-10)))).replace(tzinfo=pytz.utc).astimezone(target_timezone)\n",
    "    #cet = pytz.timezone('Europe/Berlin') #me\n",
    "    #startTime = cet.localize(startTime) #me\n",
    "    sampRate  = dict_data['rawData']['bvp']['samplingFrequency']\n",
    "    df_bvp    = pd.DataFrame({'bvp': dict_data['rawData']['bvp']['values']})\n",
    "    if sampRate > 0.0:\n",
    "        freq      = str(round(1/sampRate, 6)) + 'S'\n",
    "        time      = pd.date_range(startTime, periods=len(df_bvp), freq=freq)\n",
    "        df_bvp.index = time\n",
    "        df_bvp['sampRate'] = round(1/sampRate, 6)\n",
    "        \n",
    "    # eda\n",
    "    startTime = datetime.utcfromtimestamp((float(dict_data['rawData']['eda']['timestampStart'])/(10**(len(str(dict_data['rawData']['eda']['timestampStart']))-10)))).replace(tzinfo=pytz.utc).astimezone(target_timezone)\n",
    "    #print(\"start time using old utc_cet conversion method \", startTime)\n",
    "    #cet = pytz.timezone('Europe/Berlin') #me\n",
    "    #startTime = cet.localize(startTime) #me this stuff doesn't work so commented out\n",
    "    #print(\"start time after attempted another attempted cet conversion \", startTime)\n",
    "    sampRate  = dict_data['rawData']['eda']['samplingFrequency']\n",
    "    df_eda    = pd.DataFrame({'eda': dict_data['rawData']['eda']['values']})\n",
    "    if sampRate > 0.0:\n",
    "        freq      = str(round(1/sampRate, 2)) + 'S'\n",
    "        time      = pd.date_range(startTime, periods=len(df_eda), freq=freq)\n",
    "        df_eda.index = time\n",
    "        df_eda['sampRate'] = round(1/sampRate, 2)\n",
    "    \n",
    "    # return all data frames\n",
    "    return df_temp, df_acc, df_bvp, df_eda\n",
    "\n",
    "\n",
    "def convert_eplus_notag(dir_path, f, timezone):\n",
    "    # reading in and converting data collected with Embrace Plus\n",
    "    \n",
    "    # get list of all files of this participant\n",
    "    #fls = glob.glob(os.path.join(dir_path, part + '*.avro')) #glob.glob(os.path.join(dir_path, 'participant_data',\n",
    "                                 #'*', '*', 'raw_data', 'v*', part + '*.avro'))\n",
    "    fls = glob.glob(os.path.join(dir_path, '*.avro')) #glob.glob(os.path.join(dir_path, 'participant_data',\n",
    "                                 #'*', '*', 'raw_data', 'v*', part + '*.avro'))\n",
    "    \n",
    "    # check if any data was found\n",
    "    if len(fls) < 1:\n",
    "        print(simple_colors.red(datetime.now().strftime(\"%H:%M:%S\") + '- no data was found for participant ' + part, 'bold'))\n",
    "        f.write('\\n' + datetime.now().strftime(\"%H:%M:%S\") + '- no data was found for participant ' + part)\n",
    "        return {}\n",
    "    \n",
    "    # sort by start time in unix\n",
    "    fls = sorted(fls, key=lambda i: int(os.path.splitext(os.path.basename(i))[0][-9:]))\n",
    "    \n",
    "    # initialise empty data frames\n",
    "    ls_temp = list()\n",
    "    ls_acc  = list()\n",
    "    ls_eda  = list()\n",
    "    ls_bvp  = list()\n",
    "    \n",
    "    # loop through files\n",
    "    for fl in fls:\n",
    "        # read in the avro data\n",
    "        df_temp, df_acc, df_bvp, df_eda = read_avro(fl, timezone)\n",
    "        # check timing difference: \n",
    "        if len(ls_temp) > 0 & len(df_temp) > 0: \n",
    "            # temperature: 1Hz -> should be about 1 per second\n",
    "            idx_temp = pd.date_range(ls_temp[-1].index[-1]+pd.Timedelta(seconds=df_temp['sampRate'].iloc[0]), \n",
    "                                     df_temp.index[0]-pd.Timedelta(seconds=df_temp['sampRate'].iloc[0]), freq=str(df_temp['sampRate'].iloc[0])+'S')\n",
    "            \"\"\"\n",
    "            start_time_temp = ls_temp[-1].index[-1]+pd.Timedelta(seconds=df_temp['sampRate'].iloc[0])\n",
    "            end_time_temp = df_temp.index[0]-pd.Timedelta(seconds=df_temp['sampRate'].iloc[0])\n",
    "            #making them time-zone aware\n",
    "            start_time_temp = start_time_temp.tz_localize('Europe/Berlin') if start_time_temp.tzinfo is None else start_time_temp\n",
    "            end_time_temp = end_time_temp.tz_localize('Europe/Berlin') if end_time_temp.tzinfo is None else end_time_temp\n",
    "            \n",
    "            idx_temp = pd.date_range(start_time_temp, \n",
    "                                     end_time_temp, freq=str(df_temp['sampRate'].iloc[0])+'S', tz = 'Europe/Berlin') #me\n",
    "            \"\"\"\n",
    "            tdf_temp = pd.DataFrame(np.nan, index=idx_temp, columns=['temp'])\n",
    "            df_temp  = pd.concat([tdf_temp, df_temp])\n",
    "        \n",
    "        if len(ls_acc) > 0 & len(df_acc) > 0: \n",
    "            # acceleration: 64Hz -> should be about 1 every 15.625ms\n",
    "            idx_acc  = pd.date_range(ls_acc[-1].index[-1]+pd.Timedelta(seconds=df_acc['sampRate'].iloc[0]), \n",
    "                                     df_acc.index[0]-pd.Timedelta(seconds=df_acc['sampRate'].iloc[0]), freq=str(df_acc['sampRate'].iloc[0])+'S')\n",
    "            \"\"\"\n",
    "            start_time_acc = ls_acc[-1].index[-1]+pd.Timedelta(seconds=df_acc['sampRate'].iloc[0])\n",
    "            end_time_acc = df_acc.index[0]-pd.Timedelta(seconds=df_acc['sampRate'].iloc[0])\n",
    "            #making them time-zone aware\n",
    "            start_time_acc = start_time_acc.tz_localize('Europe/Berlin') if start_time_acc.tzinfo is None else start_time_acc\n",
    "            end_time_acc = end_time_acc.tz_localize('Europe/Berlin') if end_time_acc.tzinfo is None else end_time_acc\n",
    "            \n",
    "            idx_acc  = pd.date_range(start_time_acc, \n",
    "                                     end_time_acc, freq=str(df_acc['sampRate'].iloc[0])+'S', tz = 'Europe/Berlin') #me\n",
    "            \"\"\"\n",
    "            tdf_acc  = pd.DataFrame(np.nan, index=idx_acc, columns=['accx', 'accy', 'accz'])\n",
    "            df_acc   = pd.concat([tdf_acc, df_acc])\n",
    "        \n",
    "        if len(ls_eda) > 0 & len(df_eda) > 0:     \n",
    "            # eda: 4Hz -> should be about 1 every 250ms\n",
    "            idx_eda  = pd.date_range(ls_eda[-1].index[-1]+pd.Timedelta(seconds=df_eda['sampRate'].iloc[0]), \n",
    "                                     df_eda.index[0]-pd.Timedelta(seconds=df_eda['sampRate'].iloc[0]), freq=str(df_eda['sampRate'].iloc[0])+'S')\n",
    "            \n",
    "            \"\"\"\n",
    "            start_time_eda = ls_eda[-1].index[-1]+pd.Timedelta(seconds=df_eda['sampRate'].iloc[0])\n",
    "            end_time_eda = df_eda.index[0]-pd.Timedelta(seconds=df_eda['sampRate'].iloc[0])\n",
    "            #making them time-zone aware\n",
    "            start_time_eda = start_time_eda.tz_localize('Europe/Berlin') if start_time_eda.tzinfo is None else start_time_eda\n",
    "            end_time_eda = end_time_eda.tz_localize('Europe/Berlin') if end_time_eda.tzinfo is None else end_time_eda\n",
    "            \n",
    "            idx_eda  = pd.date_range(start_time_eda, \n",
    "                                     end_time_eda, freq=str(df_eda['sampRate'].iloc[0])+'S', tz = 'Europe/Berlin') #me\n",
    "            \"\"\"\n",
    "            tdf_eda  = pd.DataFrame(np.nan, index=idx_eda, columns=['eda'])\n",
    "            df_eda   = pd.concat([tdf_eda, df_eda])\n",
    "           \n",
    "        \n",
    "        if len(ls_bvp) > 0 & len(df_bvp) > 0:     \n",
    "            # bvp: 1Hz -> 64Hz -> should be about 1 every 15.625ms\n",
    "            idx_bvp = pd.date_range(ls_bvp[-1].index[-1]+pd.Timedelta(seconds=df_bvp['sampRate'].iloc[0]), \n",
    "                                     df_bvp.index[0]-pd.Timedelta(seconds=df_bvp['sampRate'].iloc[0]), freq=str(df_bvp['sampRate'].iloc[0])+'S')\n",
    "            \"\"\"\n",
    "            start_time_bvp = ls_bvp[-1].index[-1]+pd.Timedelta(seconds=df_bvp['sampRate'].iloc[0])\n",
    "            end_time_bvp = df_bvp.index[0]-pd.Timedelta(seconds=df_bvp['sampRate'].iloc[0])\n",
    "            #making them time-zone aware\n",
    "            start_time_bvp = start_time_bvp.tz_localize('Europe/Berlin') if start_time_bvp.tzinfo is None else start_time_bvp\n",
    "            end_time_bvp = end_time_bvp.tz_localize('Europe/Berlin') if end_time_bvp.tzinfo is None else end_time_bvp\n",
    "            \n",
    "            idx_bvp = pd.date_range(start_time_bvp, \n",
    "                                     end_time_bvp, freq=str(df_bvp['sampRate'].iloc[0])+'S', tz = 'Europe/Berlin') #me\n",
    "            \"\"\"\n",
    "            tdf_bvp  = pd.DataFrame(np.nan, index=idx_bvp, columns=['bvp'])\n",
    "            df_bvp   = pd.concat([tdf_bvp, df_bvp])\n",
    "            \n",
    "        # append to lists\n",
    "        if len(df_bvp) > 0:\n",
    "            ls_bvp.append(df_bvp)\n",
    "        if len(df_temp) > 0:\n",
    "            ls_temp.append(df_temp)\n",
    "        if len(df_acc) > 0:\n",
    "            # scale the accelometer to +-2g: \"each ADC count will be = 1/2048g\" (email from 12.12.2023)\n",
    "            df_acc[\"accx\"] = df_acc[\"accx_raw\"]/2048\n",
    "            df_acc[\"accy\"] = df_acc[\"accy_raw\"]/2048\n",
    "            df_acc[\"accz\"] = df_acc[\"accz_raw\"]/2048\n",
    "            \n",
    "            ls_acc.append(df_acc)\n",
    "        if len(df_eda) > 0:\n",
    "            ls_eda.append(df_eda)\n",
    "             #return tdf_eda, df_eda, ls_eda\n",
    "    #\"\"\"\n",
    "    # concat list of dataframes to dataframes in dictionary\n",
    "    return {\n",
    "        'temp' : pd.concat(ls_temp),\n",
    "        'acc'  : pd.concat(ls_acc),\n",
    "        'bvp'  : pd.concat(ls_bvp),\n",
    "        'eda'  : pd.concat(ls_eda)\n",
    "    }\n",
    "    #\"\"\"\n",
    "\n",
    "\n",
    "###### EDA\n",
    "\n",
    "def eda_prepro_notag(dir_out, df_eda, subject, key, winwidth, lowpass, f, timezone): #(dir_out, df_eda, subject, key, winwidth, [], f) \n",
    "    # preprocessing EDA data\n",
    "\n",
    "    # get sampling rate in Hz\n",
    "    sr = 1/df_eda['sampRate'].iloc[0]\n",
    "    print(\"sr = \", sr)\n",
    "    # if a filter was supposed to be applied\n",
    "    if isinstance(lowpass, int):\n",
    "        # check if digital filter critical frequency 0 < lowpass < fs/2\n",
    "        if (lowpass > 0) & (lowpass < sr/2):\n",
    "            fil = scipy.signal.butter(1, 5, fs = sr)\n",
    "            data = scipy.signal.sosfilt(fil, df_eda['eda'])\n",
    "        else:\n",
    "            data = df_eda['eda']\n",
    "            print(simple_colors.red('No filtering applied.', 'bold'), 'Critical frequency must be at least half the sampling rate for smoothing to be performed.')\n",
    "            f.write('\\n' + 'No filtering applied. Critical frequency must be at least half the sampling rate for smoothing to be performed.')\n",
    "    else:\n",
    "        print(\"no filtering applied\") #added by me\n",
    "        data = df_eda['eda']\n",
    "    \n",
    "    # smooth the data - same as GAUSS option in ledalab\n",
    "    df_eda['eda_smooth'] = gauss_smoothing(data, winwidth)\n",
    "\n",
    "    #return df_eda\n",
    "    \n",
    "    # process the data, including TTG to detect peaks\n",
    "    signals, info = nk.eda_process(df_eda['eda_smooth'], sampling_rate = sr)\n",
    "    #return df_eda, signals, info\n",
    "\n",
    "    \n",
    "    # combine the data frames\n",
    "    signals.index = df_eda.index\n",
    "    df_eda = signals.join(df_eda)\n",
    "    \n",
    "    \n",
    "    df_eda = df_eda.drop(['EDA_Raw', 'eda_smooth'], axis=1).rename(columns={\"eda\": \"EDA_Raw\"}, errors=\"raise\")\n",
    "    signals = df_eda.reset_index()\n",
    "    \n",
    "    # visualise the signals\n",
    "    matplotlib.rcParams['figure.figsize'] = (100, 10)\n",
    "    nk.eda_plot(signals, info)\n",
    "    plt.savefig(os.path.join(dir_out, subject + '_' + key + '_eda_signals.png'), dpi = 300)\n",
    "    \n",
    "    # close all figures\n",
    "    plt.close(\"all\") \n",
    "\n",
    "    #return df_eda, signals, info\n",
    "    \n",
    "    #filepath = the empatica folder for that day\n",
    "    \n",
    "    filepath = Path(dir_path).parent\n",
    "    print(filepath)\n",
    "    df_eda_filtered = additional_filters(df_eda, filepath, timezone) \n",
    "    # save data to csv\n",
    "    df_eda.rename(columns={\"raw\": \"EDA_Raw_noint\"}).to_csv(os.path.join(dir_out, subject + '_' + key + '_eda_signals.csv'), index = True)\n",
    "    info.pop('sampling_rate')\n",
    "    info_df = pd.DataFrame.from_dict(info)\n",
    "    info_df.to_csv(os.path.join(dir_out, subject + '_' + key + '_eda_scr.csv'), index = True)\n",
    "    df_eda_filtered.rename(columns={\"raw\": \"EDA_Raw_noint\"}).to_csv(os.path.join(dir_out, subject + '_' + key + '_eda_signals_filtered.csv'), index = True)\n",
    "    #call back the previously saved fig or re-visualise the eda figure and whereever the data has been turned NA, put red lines just like the artifact plot function\n",
    "    \n",
    "    return df_eda, df_eda_filtered, signals, info\n",
    "    #return\n",
    "    \n",
    "\"\"\"\n",
    "def additional_filters(df_eda, filepath):\n",
    "    #read in temp.csv as a dataframe from preprocessed files folder\n",
    "    #read agg eda.csv as a dataframe from aggr_p_min folder\n",
    "    #add a new column to df_eda called \"temp_data_validity\" -> +1 if within required temperature range and -1 if not; match by timestamp\n",
    "    #add a new column to df_eda called \"device_recording_validity\" -> -1 if \"device_not_recording\" or \"device_not_worn_correctly\" and +1 if not; for every\n",
    "    #now for all the rows of df_eda, if the \"temp_data_validity\" or \"device_recording_validity\" columns are -1, all eda columns are made NA\n",
    "    return df_eda\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def additional_filters(df_eda, filepath, timezone):\n",
    "    folder11 = 'aggr_p_min'\n",
    "    folder12 = 'avro_files'\n",
    "    #folder13 = 'avro2csv'\n",
    "    folder14 = 'preprocessed_files_debug'\n",
    "    folder141 = 'data_preproc_debug'\n",
    "    #read in temp.csv as a dataframe from aggr_p_min folder (not preprocessed files folder because it is data for every 1 second and the timestamps do not match. Therefore there is no coding-based advantage to using it. Moreover, a second by second data elimination is not needed. The per minute aggregated data is a better and stricter way of filtering out untrustworthy data because the entire minute's data, if it is not valid, can be eliminated.\n",
    "    for file in os.listdir(os.path.join(filepath, folder11)):\n",
    "        if file.endswith('temperature.csv'):\n",
    "            temp_file = pd.read_csv(os.path.join(filepath, folder11, file))\n",
    "    # Define the time zones\n",
    "    utc_zone = pytz.utc\n",
    "    req_zone = pytz.timezone(timezone)\n",
    "\n",
    "    # Function to convert UTC to Europe/Berlin time\n",
    "    def from_isoutc_to_req(iso_timestamp):\n",
    "        # Parse the ISO 8601 timestamp into a datetime object\n",
    "        utc_time = datetime.fromisoformat(iso_timestamp.replace(\"Z\", \"+00:00\"))\n",
    "    \n",
    "        # Localize the datetime object to UTC\n",
    "        #utc_time = utc_zone.localize(utc_time) check this line and see if it is still required\n",
    "    \n",
    "        # Convert to Berlin time\n",
    "        req_time = utc_time.astimezone(req_zone)\n",
    "        #print(req_time, type(req_time))\n",
    "    \n",
    "        return req_time #.isoformat()\n",
    "\n",
    "    # Apply the conversion function to the 'utc_timestamps' column and create a new column 'converted_timestamps'\n",
    "    temp_file['converted_timestamps'] = temp_file['timestamp_iso'].apply(from_isoutc_to_req)\n",
    "    \n",
    "    #read agg eda.csv as a dataframe from aggr_p_min folder\n",
    "    for file in os.listdir(os.path.join(filepath, folder11)):\n",
    "        if file.endswith('eda.csv'):\n",
    "            eda_aggr_file = pd.read_csv(os.path.join(filepath, folder11, file))\n",
    "\n",
    "    # Apply the conversion function to the 'utc_timestamps' column and create a new column 'converted_timestamps'\n",
    "    eda_aggr_file['converted_timestamps'] = eda_aggr_file['timestamp_iso'].apply(from_isoutc_to_req)\n",
    "\n",
    "    \n",
    "    #add a new column to df_eda called \"temp_data_validity\" -> +1 if within required temperature range and -1 if not; match by timestamp\n",
    "    #tenative min and max values => modify to verified values\n",
    "    temp_min= 30\n",
    "    temp_max = 40\n",
    "    # Create a new column in df_eda initialized with NaN\n",
    "    df_eda['temp_data_validity'] = np.nan\n",
    "\n",
    "    # Create a boolean mask for valid temperatures in temp_file\n",
    "    valid_temp_mask = (temp_file['temperature_celsius'] > temp_min) & (temp_file['temperature_celsius'] < temp_max)\n",
    "\n",
    "    # Convert the mask to 1 and -1\n",
    "    temp_validity = np.where(valid_temp_mask, 1, -1)\n",
    "\n",
    "    # Use pd.cut to bin df_eda.index based on temp_file['converted_timestamps']\n",
    "    bins = temp_file['converted_timestamps']\n",
    "    df_eda['temp_interval'] = pd.cut(df_eda.index, bins=bins, labels=False, include_lowest=True, right=False)\n",
    "\n",
    "    # Map the interval indices to their corresponding validity values\n",
    "    interval_to_validity = dict(enumerate(temp_validity[:-1]))\n",
    "    df_eda['temp_data_validity'] = df_eda['temp_interval'].map(interval_to_validity)\n",
    "\n",
    "    # Handle values before the first timestamp and after the last timestamp\n",
    "    df_eda.loc[df_eda.index < bins.min(), 'temp_data_validity'] = temp_validity[0]\n",
    "    df_eda.loc[df_eda.index >= bins.max(), 'temp_data_validity'] = temp_validity[-1]\n",
    "\n",
    "    # Drop the temporary 'temp_interval' column\n",
    "    df_eda.drop('temp_interval', axis=1, inplace=True)\n",
    "\n",
    "    #add a new column to df_eda called \"device_recording_validity\" -> -1 if \"device_not_recording\" or \"device_not_worn_correctly\" and +1 if not; for every\n",
    "    # Create a new column in df_eda initialized with NaN\n",
    "    df_eda['device_recording_validity'] = np.nan\n",
    "\n",
    "    # Create a boolean mask for valid recording entries in eda_aggr_file\n",
    "    valid_eda_rec_mask = valid_eda_rec_mask = ~((eda_aggr_file['missing_value_reason'] == 'device_not_recording') | \n",
    "                           (eda_aggr_file['missing_value_reason'] == 'device_not_worn_correctly'))#eda_aggr_file['eda_scl_usiemens'] != np.nan #(eda_aggr_file['missing_value_reason'] != 'device_not_recording') & (eda_aggr_file['missing_value_reason'] != 'device_not_worn_correctly')\n",
    "\n",
    "    # Convert the mask to 1 and -1\n",
    "    dev_rec_validity = np.where(valid_eda_rec_mask, 1, -1)\n",
    "\n",
    "    # Use pd.cut to bin df_eda.index based on eda_aggr_file['converted_timestamps']\n",
    "    bins = eda_aggr_file['converted_timestamps']\n",
    "    df_eda['eda_interval'] = pd.cut(df_eda.index, bins=bins, labels=False, include_lowest=True, right=False)\n",
    "\n",
    "    # Map the interval indices to their corresponding validity values\n",
    "    interval_to_validity = dict(enumerate(dev_rec_validity[:-1]))\n",
    "    df_eda['device_recording_validity'] = df_eda['eda_interval'].map(interval_to_validity)\n",
    "\n",
    "    # Handle values before the first timestamp and after the last timestamp\n",
    "    df_eda.loc[df_eda.index < bins.min(), 'device_recording_validity'] = dev_rec_validity[0]\n",
    "    df_eda.loc[df_eda.index >= bins.max(), 'device_recording_validity'] = dev_rec_validity[-1]\n",
    "\n",
    "    # Drop the temporary 'temp_interval' column\n",
    "    df_eda.drop('eda_interval', axis=1, inplace=True)\n",
    "\n",
    "    \"\"\"    \n",
    "    # Print some diagnostics\n",
    "    print(f\"Number of -1 entries: {(df_eda['device_recording_validity'] == -1).sum()}\")\n",
    "    print(f\"Number of 1 entries: {(df_eda['device_recording_validity'] == 1).sum()}\")\n",
    "    print(f\"Total entries: {len(df_eda)}\")\n",
    "\n",
    "    # Check the distribution of missing_value_reason in eda_aggr_file\n",
    "    print(eda_aggr_file['missing_value_reason'].value_counts())\n",
    "    \"\"\"\n",
    "    #now for all the rows of df_eda, if the \"temp_data_validity\" or \"device_recording_validity\" columns are -1, all eda columns are made NA -> maybe not\n",
    "    return df_eda\n",
    "    \n",
    "###### BVP and HR\n",
    "\n",
    "\n",
    "def bvp_prepro_notag(dir_out, df_bvp, subject, key):\n",
    "    # preprocessing BVP and HR data\n",
    "\n",
    "    # get sampling rate in Hz\n",
    "    sr  = 1/df_bvp['sampRate'].iloc[0]\n",
    "    \n",
    "    # process the data following Elgendi et al. (2013)\n",
    "    # settings: \n",
    "    #   peakwindow=0.111,\n",
    "    #   beatwindow=0.667,\n",
    "    #   beatoffset=0.02,\n",
    "    #   mindelay=0.3\n",
    "    #   minimum peak height of 0\n",
    "    signals, info = nk.ppg_process(df_bvp['bvp'], sampling_rate = sr)\n",
    "    \n",
    "    # plot the data\n",
    "    matplotlib.rcParams['figure.figsize'] = (20, 10)\n",
    "    nk.ppg_plot(signals, info)\n",
    "    plt.savefig(os.path.join(dir_out, subject + '_' + key + '_bvp_signals.png'), dpi = 300)\n",
    "    signals_split = np.array_split(signals, 10)\n",
    "    count = 0\n",
    "    for s in signals_split:\n",
    "        count = count + 1\n",
    "        # graphs can only be created when there are more than three peaks\n",
    "        if sum(s['PPG_Peaks'] == 1) > 3:\n",
    "            nk.ppg_plot(s, info)\n",
    "            plt.savefig(os.path.join(dir_out, subject + '_' + key + '_bvp_signals_' + str(count) + '.png'), dpi = 300)\n",
    "    \n",
    "    # calculate HRV\n",
    "    hrv_indices = nk.hrv(signals, sampling_rate = info['sampling_rate'], show = True)\n",
    "    plt.savefig(os.path.join(dir_out, subject + '_' + key + '_bvp_hrv.png'), dpi = 300)\n",
    "    \n",
    "    # close all figures\n",
    "    plt.close(\"all\") \n",
    "    \n",
    "    # save signals and hrv_indices to csv\n",
    "    signals.index = df_bvp.index\n",
    "    df_bvp = signals.join(df_bvp)\n",
    "    df_bvp.drop(['bvp'], axis=1).rename(columns={\"raw\": \"PPG_Raw_noint\"}).to_csv(os.path.join(dir_out, subject + '_' + key + '_bvp_signals.csv'), index = True)\n",
    "    hrv_indices.to_csv(os.path.join(dir_out, subject + '_' + key + '_bvp_hrv.csv'), index = True)\n",
    "    \n",
    "    return \n",
    "\n",
    "###### Run everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01e997e5-9b46-4d06-adf6-1cd302b01f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproPSYPHY_notag(mainfolder, dir_path, dir_out, subject_list, empatica, date, timezone, exclude = [], winwidth = 8, lowpass = 5, max_art = 50, art_cor = True): #change max_art to 100/3 - the original value\n",
    "\n",
    "    # start writing a log file\n",
    "    log_file_new = os.path.join(mainfolder, 'subject_log.txt')\n",
    "    f = open(log_file_new, \"a\")\n",
    "\n",
    "    # remove excluded participants\n",
    "    \n",
    "    for e in exclude:\n",
    "        for part in subject_list:\n",
    "            if e in part: \n",
    "                subject_list.remove(part)\n",
    "    \n",
    "    \n",
    "    # loop through the participants\n",
    "    for subject in subject_list:\n",
    "        print(subject)\n",
    "       \n",
    "        # print a message\n",
    "        print(simple_colors.blue(datetime.now().strftime(\"%H:%M:%S\") + ' - processing participant ' + subject + ' for date ' + date, 'bold'))\n",
    "        f.write('\\n\\n' + datetime.now().strftime(\"%H:%M:%S\") + ' - processing participant ' + subject + ' for date ' + date)\n",
    "\n",
    "        # read in and convert the data\n",
    "        if empatica == 'e+':\n",
    "\n",
    "            # convert eplus data\n",
    "            dict_data = convert_eplus_notag(dir_path, f, timezone) #RETURN STATMENT 2 - COMMENT OUT THE REST OF THE FUNCTION AND RETURN \n",
    "            #tdf_eda, df_eda, ls_eda = convert_eplus_notag(dir_path, f, timezone) #RETURN STATEMENT 1 - comment out the rest of the this function\n",
    "        \n",
    "        \n",
    "        # if no data was found for this participant, continue with the next one\n",
    "        if len(dict_data) < 1:\n",
    "            continue\n",
    "\n",
    "        print(simple_colors.green(datetime.now().strftime(\"%H:%M:%S\") + ' - conversion done for subject ' + subject + ' for date ' + date, 'bold'))\n",
    "        f.write('\\n' + datetime.now().strftime(\"%H:%M:%S\") + ' - conversion done')\n",
    "\n",
    "        #return dict_data\n",
    "        \n",
    "        \n",
    "        # loop through the blocks and preprocess the data\n",
    "        for key, dict_df in dict_data.items():\n",
    "            print(key)\n",
    "            \n",
    "            # detect artifacts using the EDA Explorer classifier\n",
    "            if key == 'eda':\n",
    "                    #labels  = EDA_artifact_detection(dict_df, dir_out, part, key)\n",
    "                    #data = EDA_artifact_detection(dict_df, dir_out, part, key)\n",
    "                    #data = EDA_artifact_detection(dict_df, dict_data, dir_out, part, key)\n",
    "                    labels = EDA_artifact_detection_notag(dict_data, dir_out, subject, key)\n",
    "                    #print(labels)\n",
    "            elif key == 'temp' and len(dict_df) > 0:# simply save temp and acc, if they exist\n",
    "                try:\n",
    "                    dict_df['temp'].to_csv(os.path.join(dir_out, subject + '_' + key + '_temp.csv'))\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred while saving the 'temp' data: {e}\")\n",
    "                    f.write('\\n' + datetime.now().strftime(\"%H:%M:%S\") + ' - error saving temp data '+ e)\n",
    "                    continue\n",
    "            elif key == 'acc' and len(dict_df) > 0:\n",
    "                try:\n",
    "                    dict_data['acc'].to_csv(os.path.join(dir_out, subject + '_' + key + '_acc.csv'))\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred while saving the 'acc' data: {e}\")\n",
    "                    f.write('\\n' + datetime.now().strftime(\"%H:%M:%S\") + ' - error saving acc data '+ e)\n",
    "                    continue\n",
    "            else:\n",
    "                    continue\n",
    "            #return data\n",
    "            \n",
    "            per_art = sum(labels['Binary'] == -1)*100/len(labels)\n",
    "            print(\"per_art is: \", per_art)\n",
    "            \n",
    "            # add the percent to the tags object            \n",
    "            #tags['artefact%'].loc[(tags['part'] == part) & (tags['tag'] == key)] = per_art\n",
    "            \n",
    "            # only preprocess if less than 20% artefacts\n",
    "            if per_art < max_art:\n",
    "\n",
    "                print(simple_colors.green(datetime.now().strftime(\"%H:%M:%S\") + ' - block ' + key + ': artifact detection done , for date ' + date, 'bold'))\n",
    "                f.write('\\n' + datetime.now().strftime(\"%H:%M:%S\") + ' - block ' + key + ': artifact detection done')\n",
    "\n",
    "                # replacing artefacts with NaNs and then interpolating them\n",
    "                if art_cor:\n",
    "                    #return dict_data['eda'], labels\n",
    "                   \n",
    "                    #df_eda, df_bvp = na_missing(dict_df['eda'], dict_df['bvp'], labels)\n",
    "                    df_eda, df_bvp = na_missing(dict_data['eda'], dict_data['bvp'], labels) #me\n",
    "                    #return df_eda, labels\n",
    "                    \n",
    "                    df_eda, df_bvp, [], [] = int_missing(df_eda, df_bvp, [], [], f)\n",
    "                    #return df_eda\n",
    "                    \n",
    "                    print(simple_colors.green(datetime.now().strftime(\"%H:%M:%S\") + ' - block ' + key + ': artifact correction done, for date ' + date, 'bold'))\n",
    "                    f.write('\\n' + datetime.now().strftime(\"%H:%M:%S\") + ' - block ' + key + ': artifact correction done')\n",
    "                else:\n",
    "                    df_eda = dict_df['eda']\n",
    "                    df_bvp = dict_df['bvp']\n",
    "\n",
    "                # preprocess EDA and BVP data with neurokit\n",
    "                df_eda, df_eda_filtered, signals, info = eda_prepro_notag(dir_out, df_eda, subject, key, winwidth, [], f, timezone) \n",
    "                #return df_eda\n",
    "                \n",
    "                #bvp_prepro_notag(dir_out, df_bvp, subject, key)\n",
    "\n",
    "                \n",
    "                \n",
    "                print(simple_colors.green(datetime.now().strftime(\"%H:%M:%S\") + ' - block ' + key + ': preprocessing done' + ' for date ' + date, 'bold'))\n",
    "                f.write('\\n' + datetime.now().strftime(\"%H:%M:%S\") + ' - block ' + key + ': preprocessing done')\n",
    "\n",
    "                \n",
    "\n",
    "            else: \n",
    "\n",
    "                print(simple_colors.red(datetime.now().strftime(\"%H:%M:%S\") + ' - block ' + key + ': STOPPED due to ' + str(round(per_art,2)) + '% artefacts', 'bold'))\n",
    "                f.write('\\n' + datetime.now().strftime(\"%H:%M:%S\") + ' - block ' + key + ': STOPPED due to ' + str(round(per_art,2)) + '% artefacts')\n",
    "                f.close()\n",
    "                return None, None, None, None\n",
    "                \n",
    "    #tags.to_csv(tag_file[:-4] + '_prepro.csv')\n",
    "    f.close()\n",
    "    return df_eda, df_eda_filtered, signals, info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4a7ed80-d61e-4bb7-968f-a9c29e386858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter the subject folder:  C:\\Users\\Ananya Rao\\Documents\\CAM_LMU\\LMU_Stream_HC_002_4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Code block to reference the necessary folders\n",
    "\"\"\"\n",
    "parentfolder = input('enter the subject folder: ') \n",
    "\n",
    "\"\"\"\n",
    "names of folders to be used\n",
    "\"\"\"\n",
    "folder1 = 'empatica'\n",
    "folder2 = 'saved_figures'\n",
    "\n",
    "folder11 = 'aggr_p_min'\n",
    "folder12 = 'avro_files'\n",
    "folder13 = 'avro2csv'\n",
    "folder14 = 'preprocessed_files_debug'\n",
    "folder141 = 'data_preproc_debug'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de6507bf-7720-43a6-94c9-3c92e8a853d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04112023_n1_05112023_d\n",
      "LMU_Stream_HC_002\n",
      "\u001b[1;34m02:17:49 - processing participant LMU_Stream_HC_002 for date 04112023_n1_05112023_d\u001b[0m\n",
      "\u001b[1;32m02:20:01 - conversion done for subject LMU_Stream_HC_002 for date 04112023_n1_05112023_d\u001b[0m\n",
      "temp\n",
      "acc\n",
      "An error occurred while saving the 'acc' data: [Errno 28] No space left on device\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"OSError\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32mF:\\anaconda\\envs\\empatica\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:266\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    257\u001b[0m     handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    258\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    264\u001b[0m )\n\u001b[1;32m--> 266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mF:\\anaconda\\envs\\empatica\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:271\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[1;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_body()\n",
      "File \u001b[1;32mF:\\anaconda\\envs\\empatica\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:309\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_chunk(start_i, end_i)\n",
      "File \u001b[1;32mF:\\anaconda\\envs\\empatica\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:320\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    319\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_format_native_types(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[1;32m--> 320\u001b[0m libwriters\u001b[38;5;241m.\u001b[39mwrite_csv_rows(\n\u001b[0;32m    321\u001b[0m     data,\n\u001b[0;32m    322\u001b[0m     ix,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlevels,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcols,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter,\n\u001b[0;32m    326\u001b[0m )\n",
      "File \u001b[1;32mwriters.pyx:55\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 62\u001b[0m, in \u001b[0;36mpreproPSYPHY_notag\u001b[1;34m(mainfolder, dir_path, dir_out, subject_list, empatica, date, timezone, exclude, winwidth, lowpass, max_art, art_cor)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 62\u001b[0m     dict_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dir_out, subject \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_acc.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mF:\\anaconda\\envs\\empatica\\Lib\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3900\u001b[0m )\n\u001b[1;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3903\u001b[0m     path_or_buf,\n\u001b[0;32m   3904\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3905\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3906\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3907\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3908\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3909\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3910\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3911\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3912\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3913\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3914\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3915\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3916\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3917\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3918\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3919\u001b[0m )\n",
      "File \u001b[1;32mF:\\anaconda\\envs\\empatica\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1151\u001b[0m )\n\u001b[1;32m-> 1152\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n",
      "File \u001b[1;32mF:\\anaconda\\envs\\empatica\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    250\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    251\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    252\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    253\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    254\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    264\u001b[0m     )\n",
      "File \u001b[1;32mF:\\anaconda\\envs\\empatica\\Lib\\site-packages\\pandas\\io\\common.py:142\u001b[0m, in \u001b[0;36mIOHandles.__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mF:\\anaconda\\envs\\empatica\\Lib\\site-packages\\pandas\\io\\common.py:134\u001b[0m, in \u001b[0;36mIOHandles.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreated_handles:\n\u001b[1;32m--> 134\u001b[0m     handle\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreated_handles \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m     timezone \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEurope/Berlin\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#default timezone; enter required timezone if different\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m#preprocess\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     df_eda, df_eda_filtered, signals, info \u001b[38;5;241m=\u001b[39m preproPSYPHY_notag(mainfolder, dir_path, dir_out, subject_list, empatica,  date, timezone, exclude)\n\u001b[0;32m     53\u001b[0m     count \u001b[38;5;241m=\u001b[39m count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    21:44:12 - processing participant LMU_Stream_ASD_001 for date 15_3_24_n7_16_3_24_d\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m21:46:47 - conversion done for subject LMU_Stream_ASD_001 for date 15_3_24_n7_16_3_24_d\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m21:52:34 - block eda: STOPPED due to 41.07% artefacts\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 66\u001b[0m, in \u001b[0;36mpreproPSYPHY_notag\u001b[1;34m(mainfolder, dir_path, dir_out, subject_list, empatica, date, timezone, exclude, winwidth, lowpass, max_art, art_cor)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while saving the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 66\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m - error saving acc data \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m e)\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"OSError\") to str"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "playing around to add in temperature and device informed filters\n",
    "\"\"\"\n",
    "#HC_002\n",
    "\"\"\"\n",
    "need to preprocess files for each and every avro file generated for the day. \n",
    "first generate all the new required directories\n",
    "\"\"\"\n",
    "\n",
    "count = 0\n",
    "for subfolder in os.listdir(parentfolder):\n",
    "    if count>20:\n",
    "        print(\"one subfolder done, exiting\") #back when only one subfolder needed to be processed\n",
    "        break\n",
    "    if not(os.path.exists(os.path.join(parentfolder, subfolder, folder1))):\n",
    "        continue\n",
    "    \n",
    "    \"\"\"\n",
    "    elif subfolder not in ['14_3_24_n6_15_3_24_d']: #['14_3_24_n6_15_3_24_d', '15_3_24_n7_16_3_24_d', '08_3_24_n1_9_3_24_d' ,'09_3_24_n2_10_3_24_d','11_3_24_n3_12_3_24_d', '12_3_24_n4_13_3_24_d', '13_3_24_n5_14_3_24_d', '15_3_24_n7_16_3_24_d'] : #find out later what the issue with '14_3_24_n6_15_3_24_d' is\n",
    "        continue\n",
    "    \"\"\"\n",
    "    if not(os.path.exists(os.path.join(parentfolder, subfolder, folder1, folder14))): #modify this after asd_001\n",
    "        dir14 = os.mkdir(os.path.join(parentfolder, subfolder, folder1, folder14))        \n",
    "        Dir= os.mkdir(os.path.join(parentfolder, subfolder, folder1, folder14, folder141))\n",
    "        print(subfolder)\n",
    "    \n",
    "    if not(os.path.exists(os.path.join(parentfolder, subfolder, folder1, folder14))):\n",
    "        dir14 = os.mkdir(os.path.join(parentfolder, subfolder, folder1, folder14))        \n",
    "        Dir= os.mkdir(os.path.join(parentfolder, subfolder, folder1, folder14, folder141))\n",
    "    \n",
    "    \n",
    "    #entering the relevant file paths\n",
    "    # path to the data directory\n",
    "    dir_path = os.path.join(parentfolder, subfolder, folder1, folder12)\n",
    "    # path to the output directory\n",
    "    dir_out = os.path.join(parentfolder, subfolder, folder1, folder14, folder141) #os.path.join(os.getcwd(), 'E+/1/1/preprocessed_data')\n",
    "    # which empatica version was used: 'e4' or 'e+'?\n",
    "    empatica = 'e+'\n",
    "    # list of participants that should not be processed\n",
    "    exclude  = [\"LMU_Stream_ASD_001\", \"LMU_Stream_HC_001\"]\n",
    "\n",
    "    #subject\n",
    "    subject_list = [\"LMU_Stream_HC_002\",\"LMU_Stream_ASD_001\", \"LMU_Stream_HC_001\"]\n",
    "    #to store the logs\n",
    "    mainfolder = os.path.join(parentfolder, subfolder, folder1, folder14)\n",
    "    #date\n",
    "    date = subfolder\n",
    "    #timezone \n",
    "    timezone = 'Europe/Berlin' #default timezone; enter required timezone if different\n",
    "    #preprocess\n",
    "    df_eda, df_eda_filtered, signals, info = preproPSYPHY_notag(mainfolder, dir_path, dir_out, subject_list, empatica,  date, timezone, exclude)\n",
    "\n",
    "    count = count+1\n",
    "\n",
    "    \"\"\"\n",
    "    21:44:12 - processing participant LMU_Stream_ASD_001 for date 15_3_24_n7_16_3_24_d\n",
    "21:46:47 - conversion done for subject LMU_Stream_ASD_001 for date 15_3_24_n7_16_3_24_d\n",
    "temp\n",
    "acc\n",
    "bvp\n",
    "eda\n",
    "from getWaveletData, starttime is:  2024-03-16 01:12:36.750000+01:00 <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
    "per_art is:  41.069977950562844\n",
    "21:52:34 - block eda: STOPPED due to 41.07% artefacts\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8142d8-1114-4fd5-8a45-b955093a0724",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. some cleanup of the above cells required.\n",
    "2. inclusion of code to handle conversion of e4 data - debatable - if time permits - cancelled\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
